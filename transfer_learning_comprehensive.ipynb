{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning: Comprehensive Analysis with Extended Training\n",
    "\n",
    "**Comprehensive multi-seed experiment with extended epochs and multiple accuracy thresholds**\n",
    "\n",
    "## Key Features:\n",
    "- âœ… Extended training: 30K epochs for baseline (to capture grokking)\n",
    "- âœ… Multiple accuracy thresholds: 90%, 95%, 99%, **99.9%**\n",
    "- âœ… Grokking moment detection\n",
    "- âœ… Google Drive persistence\n",
    "- âœ… Statistical analysis across N seeds\n",
    "- âœ… Publication-quality visualizations\n",
    "\n",
    "## Research Question:\n",
    "Does transfer from a grokked addition model enable rapid generalization on subtraction,\n",
    "bypassing the typical 10K+ epoch \"grokking delay\"?\n",
    "\n",
    "**Expected Runtime:** ~6-8 hours on GPU (5 seeds Ã— 2 conditions with extended epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== EXPERIMENT CONFIGURATION ==========\n",
    "\n",
    "# Number of random seeds for statistical robustness\n",
    "NUM_SEEDS = 5\n",
    "SEEDS = [42, 123, 456, 789, 1024]\n",
    "\n",
    "# Training epochs per condition\n",
    "TRANSFER_EPOCHS = 10000   # Transfer converges quickly but we track to 10K for complete picture\n",
    "BASELINE_EPOCHS = 30000   # Baseline needs time to grok (typically 5K-20K epochs)\n",
    "\n",
    "# Accuracy thresholds to track\n",
    "THRESHOLDS = [0.90, 0.95, 0.99, 0.999]  # 90%, 95%, 99%, 99.9%\n",
    "\n",
    "# Source checkpoint\n",
    "CHECKPOINT_PATH = 'saved_runs/wd_10-1_mod_addition_loss_curve.pth'\n",
    "\n",
    "# Save checkpoints every N epochs (for analysis)\n",
    "SAVE_CHECKPOINT_EVERY = 1000\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"COMPREHENSIVE TRANSFER LEARNING EXPERIMENT\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nSeeds: {SEEDS} (N={NUM_SEEDS})\")\n",
    "print(f\"Transfer epochs: {TRANSFER_EPOCHS:,}\")\n",
    "print(f\"Baseline epochs: {BASELINE_EPOCHS:,}\")\n",
    "print(f\"Accuracy thresholds: {[f'{t:.1%}' for t in THRESHOLDS]}\")\n",
    "print(f\"\\nEstimated runtime: ~6-8 hours on GPU\")\n",
    "print(f\"Total experiments: {NUM_SEEDS * 2} ({NUM_SEEDS} seeds Ã— 2 conditions)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create experiment directory with timestamp\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "DRIVE_BASE = '/content/drive/MyDrive/grokking_transfer_experiments'\n",
    "EXPERIMENT_DIR = f'{DRIVE_BASE}/comprehensive_run_{timestamp}'\n",
    "\n",
    "os.makedirs(EXPERIMENT_DIR, exist_ok=True)\n",
    "os.makedirs(f'{EXPERIMENT_DIR}/figures', exist_ok=True)\n",
    "os.makedirs(f'{EXPERIMENT_DIR}/checkpoints', exist_ok=True)\n",
    "os.makedirs(f'{EXPERIMENT_DIR}/results', exist_ok=True)\n",
    "\n",
    "print(f\"âœ“ Google Drive mounted\")\n",
    "print(f\"âœ“ Experiment directory: {EXPERIMENT_DIR}\")\n",
    "\n",
    "# Save configuration\n",
    "import json\n",
    "config_dict = {\n",
    "    'num_seeds': NUM_SEEDS,\n",
    "    'seeds': SEEDS,\n",
    "    'transfer_epochs': TRANSFER_EPOCHS,\n",
    "    'baseline_epochs': BASELINE_EPOCHS,\n",
    "    'thresholds': THRESHOLDS,\n",
    "    'checkpoint_path': CHECKPOINT_PATH,\n",
    "    'timestamp': timestamp\n",
    "}\n",
    "with open(f'{EXPERIMENT_DIR}/config.json', 'w') as f:\n",
    "    json.dump(config_dict, f, indent=2)\n",
    "print(f\"âœ“ Saved configuration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Clone Repo and Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository\n",
    "if not os.path.exists('progress-measures-paper-extension'):\n",
    "    !git clone https://github.com/Junekhunter/progress-measures-paper-extension.git\n",
    "os.chdir('progress-measures-paper-extension')\n",
    "print(f\"Working directory: {os.getcwd()}\")\n",
    "\n",
    "# Install dependencies\n",
    "!pip install -q einops\n",
    "\n",
    "# Imports\n",
    "import sys\n",
    "sys.path.insert(0, '.')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import replace\n",
    "import random\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "from transformers import Transformer, Config, gen_train_test, full_loss\n",
    "import helpers\n",
    "\n",
    "print(\"\\nâœ“ All imports successful!\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Grokked Addition Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load checkpoint\n",
    "print(f\"Loading checkpoint: {CHECKPOINT_PATH}\")\n",
    "checkpoint = torch.load(CHECKPOINT_PATH, map_location='cpu')\n",
    "\n",
    "# Verify it's grokked\n",
    "if 'test_losses' in checkpoint:\n",
    "    final_test_loss = checkpoint['test_losses'][-1]\n",
    "    if final_test_loss < 0.01:\n",
    "        print(f\"âœ“ Model is FULLY GROKKED (test loss: {final_test_loss:.6f})\")\n",
    "    else:\n",
    "        print(f\"âš  Warning: Model may not be fully grokked (test loss: {final_test_loss:.6f})\")\n",
    "\n",
    "# Create config\n",
    "addition_config = Config(\n",
    "    lr=1e-3,\n",
    "    weight_decay=1.0,\n",
    "    p=113,\n",
    "    d_model=128,\n",
    "    fn_name='add',\n",
    "    frac_train=0.3,\n",
    "    num_epochs=50000,\n",
    "    seed=0,\n",
    "    device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    ")\n",
    "\n",
    "# Load grokked model\n",
    "grokked_addition_model = Transformer(addition_config, use_cache=False)\n",
    "grokked_addition_model.to(addition_config.device)\n",
    "\n",
    "if 'model' in checkpoint:\n",
    "    grokked_addition_model.load_state_dict(checkpoint['model'])\n",
    "elif 'state_dicts' in checkpoint:\n",
    "    grokked_addition_model.load_state_dict(checkpoint['state_dicts'][-1])\n",
    "\n",
    "print(\"âœ“ Grokked addition model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Function with Multiple Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_comprehensive_tracking(model, config, num_epochs, condition_name, seed_label):\n",
    "    \"\"\"\n",
    "    Train model with comprehensive tracking of multiple accuracy thresholds and grokking detection.\n",
    "    \n",
    "    Args:\n",
    "        model: Transformer model\n",
    "        config: Config object\n",
    "        num_epochs: Number of training epochs\n",
    "        condition_name: 'transfer' or 'baseline'\n",
    "        seed_label: Label for progress bar\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with comprehensive metrics\n",
    "    \"\"\"\n",
    "    model.to(config.device)\n",
    "    model.train()\n",
    "    \n",
    "    optimizer = optim.AdamW(model.parameters(), lr=config.lr, weight_decay=config.weight_decay, betas=(0.9, 0.98))\n",
    "    scheduler = optim.lr_scheduler.LambdaLR(optimizer, lambda step: min(step/10, 1))\n",
    "    \n",
    "    train_data, test_data = gen_train_test(config)\n",
    "    \n",
    "    # Tracking\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    test_accuracies = []\n",
    "    \n",
    "    # Track when each threshold is reached\n",
    "    threshold_epochs = {t: None for t in THRESHOLDS}\n",
    "    \n",
    "    # Grokking detection (sudden test loss drop)\n",
    "    grokking_epoch = None\n",
    "    window_size = 100\n",
    "    \n",
    "    # Checkpoints to save\n",
    "    checkpoint_epochs = []\n",
    "    \n",
    "    start_time = time.time()\n",
    "    pbar = tqdm(range(num_epochs), desc=f\"{condition_name.capitalize()} {seed_label}\")\n",
    "    \n",
    "    for epoch in pbar:\n",
    "        # Training step\n",
    "        train_loss = full_loss(config, model, train_data)\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Evaluation\n",
    "        with torch.no_grad():\n",
    "            test_loss = full_loss(config, model, test_data)\n",
    "            \n",
    "            test_tensor = torch.tensor(test_data).to(config.device)\n",
    "            logits = model(test_tensor)[:, -1]\n",
    "            predictions = logits.argmax(dim=-1)\n",
    "            labels = torch.tensor([config.fn(i, j) for i, j, _ in test_data]).to(config.device)\n",
    "            test_accuracy = (predictions == labels).float().mean().item()\n",
    "        \n",
    "        train_losses.append(train_loss.item())\n",
    "        test_losses.append(test_loss.item())\n",
    "        test_accuracies.append(test_accuracy)\n",
    "        \n",
    "        # Check thresholds\n",
    "        for threshold in THRESHOLDS:\n",
    "            if threshold_epochs[threshold] is None and test_accuracy >= threshold:\n",
    "                threshold_epochs[threshold] = epoch\n",
    "                if threshold == 0.999:  # Special logging for 99.9%\n",
    "                    print(f\"\\nðŸŽ¯ Reached 99.9% accuracy at epoch {epoch}!\")\n",
    "        \n",
    "        # Detect grokking (sudden test loss drop)\n",
    "        if grokking_epoch is None and epoch >= window_size:\n",
    "            recent_avg = np.mean(test_losses[epoch-window_size:epoch-10])\n",
    "            current_avg = np.mean(test_losses[epoch-10:epoch])\n",
    "            if recent_avg - current_avg > 1.0:  # Significant drop\n",
    "                grokking_epoch = epoch\n",
    "                print(f\"\\nâš¡ Grokking detected at epoch {epoch}! (test loss dropped by {recent_avg - current_avg:.2f})\")\n",
    "        \n",
    "        # Save checkpoint periodically\n",
    "        if epoch % SAVE_CHECKPOINT_EVERY == 0 and epoch > 0:\n",
    "            checkpoint_epochs.append(epoch)\n",
    "        \n",
    "        # Update progress bar\n",
    "        if epoch % 100 == 0:\n",
    "            pbar.set_postfix({\n",
    "                'acc': f'{test_accuracy:.4f}',\n",
    "                'train_loss': f'{train_loss.item():.4f}',\n",
    "                'test_loss': f'{test_loss.item():.4f}'\n",
    "            })\n",
    "    \n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "    \n",
    "    return {\n",
    "        'train_losses': train_losses,\n",
    "        'test_losses': test_losses,\n",
    "        'test_accuracies': test_accuracies,\n",
    "        'threshold_epochs': threshold_epochs,\n",
    "        'grokking_epoch': grokking_epoch,\n",
    "        'final_test_accuracy': test_accuracies[-1],\n",
    "        'final_train_loss': train_losses[-1],\n",
    "        'final_test_loss': test_losses[-1],\n",
    "        'training_time': training_time,\n",
    "        'model_state': model.state_dict(),\n",
    "        'seed': config.seed,\n",
    "        'condition': condition_name,\n",
    "        'num_epochs': num_epochs\n",
    "    }\n",
    "\n",
    "print(\"âœ“ Training function defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Comprehensive Multi-Seed Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_transfer_results = []\n",
    "all_baseline_results = []\n",
    "\n",
    "experiment_start = time.time()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"STARTING COMPREHENSIVE EXPERIMENTS\")\n",
    "print(f\"Total experiments: {NUM_SEEDS * 2}\")\n",
    "print(f\"Estimated time: 6-8 hours\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for i, seed in enumerate(SEEDS):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"SEED {i+1}/{NUM_SEEDS}: {seed}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Create config for this seed\n",
    "    subtraction_config = replace(\n",
    "        addition_config,\n",
    "        fn_name='subtract',\n",
    "        seed=seed\n",
    "    )\n",
    "    \n",
    "    # ===== TRANSFER LEARNING =====\n",
    "    print(f\"\\nðŸ”„ TRANSFER LEARNING (seed {seed})\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    transfer_model = Transformer(subtraction_config, use_cache=False)\n",
    "    transfer_model.load_state_dict(grokked_addition_model.state_dict())\n",
    "    transfer_model.to(subtraction_config.device)\n",
    "    \n",
    "    transfer_results = train_with_comprehensive_tracking(\n",
    "        transfer_model,\n",
    "        subtraction_config,\n",
    "        TRANSFER_EPOCHS,\n",
    "        'transfer',\n",
    "        f\"seed {seed}\"\n",
    "    )\n",
    "    \n",
    "    all_transfer_results.append(transfer_results)\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\nâœ“ Transfer Results (seed {seed}):\")\n",
    "    print(f\"  Final accuracy: {transfer_results['final_test_accuracy']:.4f}\")\n",
    "    for threshold in THRESHOLDS:\n",
    "        epoch = transfer_results['threshold_epochs'][threshold]\n",
    "        if epoch is not None:\n",
    "            print(f\"  {threshold:.1%} at epoch: {epoch}\")\n",
    "        else:\n",
    "            print(f\"  {threshold:.1%}: NOT REACHED\")\n",
    "    print(f\"  Training time: {transfer_results['training_time']/60:.1f} min\")\n",
    "    \n",
    "    # Save checkpoint\n",
    "    torch.save(transfer_results, f\"{EXPERIMENT_DIR}/checkpoints/transfer_seed{seed}_comprehensive.pth\")\n",
    "    \n",
    "    # ===== BASELINE =====\n",
    "    print(f\"\\nðŸŽ² BASELINE (seed {seed})\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    baseline_model = Transformer(subtraction_config, use_cache=False)\n",
    "    baseline_model.to(subtraction_config.device)\n",
    "    \n",
    "    baseline_results = train_with_comprehensive_tracking(\n",
    "        baseline_model,\n",
    "        subtraction_config,\n",
    "        BASELINE_EPOCHS,\n",
    "        'baseline',\n",
    "        f\"seed {seed}\"\n",
    "    )\n",
    "    \n",
    "    all_baseline_results.append(baseline_results)\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\nâœ“ Baseline Results (seed {seed}):\")\n",
    "    print(f\"  Final accuracy: {baseline_results['final_test_accuracy']:.4f}\")\n",
    "    for threshold in THRESHOLDS:\n",
    "        epoch = baseline_results['threshold_epochs'][threshold]\n",
    "        if epoch is not None:\n",
    "            print(f\"  {threshold:.1%} at epoch: {epoch}\")\n",
    "        else:\n",
    "            print(f\"  {threshold:.1%}: NOT REACHED\")\n",
    "    if baseline_results['grokking_epoch'] is not None:\n",
    "        print(f\"  âš¡ Grokking at epoch: {baseline_results['grokking_epoch']}\")\n",
    "    print(f\"  Training time: {baseline_results['training_time']/60:.1f} min\")\n",
    "    \n",
    "    # Save checkpoint\n",
    "    torch.save(baseline_results, f\"{EXPERIMENT_DIR}/checkpoints/baseline_seed{seed}_comprehensive.pth\")\n",
    "    \n",
    "    # Free GPU memory\n",
    "    del transfer_model, baseline_model\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # Progress update\n",
    "    experiments_done = (i + 1) * 2\n",
    "    total_experiments = NUM_SEEDS * 2\n",
    "    elapsed = time.time() - experiment_start\n",
    "    estimated_total = elapsed / experiments_done * total_experiments\n",
    "    remaining = estimated_total - elapsed\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Progress: {experiments_done}/{total_experiments} experiments complete\")\n",
    "    print(f\"   Elapsed: {elapsed/3600:.1f}h | Remaining: ~{remaining/3600:.1f}h\")\n",
    "\n",
    "total_time = time.time() - experiment_start\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"âœ… ALL EXPERIMENTS COMPLETE!\")\n",
    "print(f\"Total time: {total_time/3600:.2f} hours\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate Results and Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "def calculate_stats(values):\n",
    "    \"\"\"Calculate mean, std, and 95% CI\"\"\"\n",
    "    values = [v for v in values if v is not None]\n",
    "    if len(values) == 0:\n",
    "        return None, None, None, None, 0\n",
    "    \n",
    "    mean = np.mean(values)\n",
    "    std = np.std(values, ddof=1) if len(values) > 1 else 0\n",
    "    \n",
    "    if len(values) > 1:\n",
    "        ci = stats.t.interval(0.95, len(values)-1, loc=mean, scale=stats.sem(values))\n",
    "    else:\n",
    "        ci = (mean, mean)\n",
    "    \n",
    "    return mean, std, ci[0], ci[1], len(values)\n",
    "\n",
    "# Aggregate statistics for each threshold\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPREHENSIVE STATISTICAL ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "stats_dict = {\n",
    "    'config': config_dict,\n",
    "    'thresholds': {}\n",
    "}\n",
    "\n",
    "for threshold in THRESHOLDS:\n",
    "    print(f\"\\nðŸ“Š {threshold:.1%} Accuracy Threshold:\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Extract epochs for this threshold\n",
    "    transfer_epochs = [r['threshold_epochs'][threshold] for r in all_transfer_results]\n",
    "    baseline_epochs = [r['threshold_epochs'][threshold] for r in all_baseline_results]\n",
    "    \n",
    "    # Calculate stats\n",
    "    t_mean, t_std, t_ci_low, t_ci_high, t_n = calculate_stats(transfer_epochs)\n",
    "    b_mean, b_std, b_ci_low, b_ci_high, b_n = calculate_stats(baseline_epochs)\n",
    "    \n",
    "    if t_mean is not None:\n",
    "        print(f\"  Transfer:  {t_mean:.1f} Â± {t_std:.1f} epochs (N={t_n}/{NUM_SEEDS} reached)\")\n",
    "        print(f\"             95% CI: [{t_ci_low:.1f}, {t_ci_high:.1f}]\")\n",
    "    else:\n",
    "        print(f\"  Transfer:  NOT REACHED by any seed\")\n",
    "    \n",
    "    if b_mean is not None:\n",
    "        print(f\"  Baseline:  {b_mean:.1f} Â± {b_std:.1f} epochs (N={b_n}/{NUM_SEEDS} reached)\")\n",
    "        print(f\"             95% CI: [{b_ci_low:.1f}, {b_ci_high:.1f}]\")\n",
    "    else:\n",
    "        print(f\"  Baseline:  NOT REACHED by any seed\")\n",
    "    \n",
    "    # Calculate speedup if both reached\n",
    "    speedup = None\n",
    "    if t_mean is not None and b_mean is not None:\n",
    "        speedup = b_mean / t_mean\n",
    "        improvement = b_mean - t_mean\n",
    "        print(f\"\\n  ðŸš€ Speedup: {speedup:.2f}x faster\")\n",
    "        print(f\"  ðŸ“‰ Saved: {improvement:.1f} epochs ({improvement/b_mean*100:.1f}% reduction)\")\n",
    "    \n",
    "    # Save to dict\n",
    "    stats_dict['thresholds'][threshold] = {\n",
    "        'transfer': {'mean': t_mean, 'std': t_std, 'ci': [t_ci_low, t_ci_high], 'n_reached': t_n, 'values': transfer_epochs},\n",
    "        'baseline': {'mean': b_mean, 'std': b_std, 'ci': [b_ci_low, b_ci_high], 'n_reached': b_n, 'values': baseline_epochs},\n",
    "        'speedup': speedup\n",
    "    }\n",
    "\n",
    "# Final accuracies\n",
    "print(f\"\\nðŸ“Š Final Test Accuracy:\")\n",
    "print(\"-\" * 80)\n",
    "transfer_final = [r['final_test_accuracy'] for r in all_transfer_results]\n",
    "baseline_final = [r['final_test_accuracy'] for r in all_baseline_results]\n",
    "\n",
    "print(f\"  Transfer: {np.mean(transfer_final):.4f} Â± {np.std(transfer_final):.4f}\")\n",
    "print(f\"  Baseline: {np.mean(baseline_final):.4f} Â± {np.std(baseline_final):.4f}\")\n",
    "\n",
    "stats_dict['final_accuracy'] = {\n",
    "    'transfer': {'mean': np.mean(transfer_final), 'std': np.std(transfer_final), 'values': transfer_final},\n",
    "    'baseline': {'mean': np.mean(baseline_final), 'std': np.std(baseline_final), 'values': baseline_final}\n",
    "}\n",
    "\n",
    "# Grokking epochs for baseline\n",
    "print(f\"\\nâš¡ Grokking Detection (Baseline only):\")\n",
    "print(\"-\" * 80)\n",
    "grokking_epochs = [r['grokking_epoch'] for r in all_baseline_results if r['grokking_epoch'] is not None]\n",
    "if len(grokking_epochs) > 0:\n",
    "    print(f\"  Detected in {len(grokking_epochs)}/{NUM_SEEDS} baseline runs\")\n",
    "    print(f\"  Mean grokking epoch: {np.mean(grokking_epochs):.1f} Â± {np.std(grokking_epochs):.1f}\")\n",
    "else:\n",
    "    print(f\"  No grokking moments detected (gradual learning)\")\n",
    "\n",
    "stats_dict['grokking'] = {\n",
    "    'n_detected': len(grokking_epochs),\n",
    "    'epochs': grokking_epochs\n",
    "}\n",
    "\n",
    "# Save statistics\n",
    "with open(f'{EXPERIMENT_DIR}/results/comprehensive_stats.json', 'w') as f:\n",
    "    json.dump(stats_dict, f, indent=2)\n",
    "\n",
    "print(f\"\\nâœ“ Saved comprehensive statistics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization: Publication-Quality Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare curves (pad baseline to match transfer length for plotting)\n",
    "transfer_curves = np.array([r['test_accuracies'] for r in all_transfer_results])\n",
    "baseline_curves_full = [r['test_accuracies'] for r in all_baseline_results]\n",
    "\n",
    "# For joint plotting, we'll handle different lengths\n",
    "transfer_mean = transfer_curves.mean(axis=0)\n",
    "transfer_std = transfer_curves.std(axis=0)\n",
    "\n",
    "# Compute baseline stats at each epoch (handling variable lengths)\n",
    "max_baseline_len = max(len(c) for c in baseline_curves_full)\n",
    "baseline_curves_padded = []\n",
    "for curve in baseline_curves_full:\n",
    "    padded = list(curve) + [curve[-1]] * (max_baseline_len - len(curve))\n",
    "    baseline_curves_padded.append(padded)\n",
    "baseline_curves_padded = np.array(baseline_curves_padded)\n",
    "\n",
    "baseline_mean = baseline_curves_padded.mean(axis=0)\n",
    "baseline_std = baseline_curves_padded.std(axis=0)\n",
    "\n",
    "print(\"âœ“ Prepared data for visualization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive figure\n",
    "fig = plt.figure(figsize=(20, 16))\n",
    "gs = fig.add_gridspec(4, 3, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# Plot 1: Transfer Learning Progress\n",
    "ax1 = fig.add_subplot(gs[0, :])\n",
    "epochs_t = np.arange(len(transfer_mean))\n",
    "ax1.plot(epochs_t, transfer_mean, 'b-', linewidth=2.5, label='Transfer Learning')\n",
    "ax1.fill_between(epochs_t, transfer_mean - transfer_std, transfer_mean + transfer_std,\n",
    "                 alpha=0.3, color='blue')\n",
    "for threshold in THRESHOLDS:\n",
    "    ax1.axhline(y=threshold, color='red', linestyle='--', alpha=0.4, linewidth=1)\n",
    "    ax1.text(len(epochs_t)*0.02, threshold + 0.01, f'{threshold:.1%}', fontsize=9, color='red')\n",
    "ax1.set_xlabel('Epoch', fontsize=13)\n",
    "ax1.set_ylabel('Test Accuracy', fontsize=13)\n",
    "ax1.set_title(f'Transfer Learning: Test Accuracy (N={NUM_SEEDS} seeds)', fontsize=15, fontweight='bold')\n",
    "ax1.legend(fontsize=11)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_ylim([0, 1.05])\n",
    "\n",
    "# Plot 2: Baseline Progress\n",
    "ax2 = fig.add_subplot(gs[1, :])\n",
    "epochs_b = np.arange(len(baseline_mean))\n",
    "ax2.plot(epochs_b, baseline_mean, 'orange', linewidth=2.5, label='Baseline (Random Init)')\n",
    "ax2.fill_between(epochs_b, baseline_mean - baseline_std, baseline_mean + baseline_std,\n",
    "                 alpha=0.3, color='orange')\n",
    "for threshold in THRESHOLDS:\n",
    "    ax2.axhline(y=threshold, color='red', linestyle='--', alpha=0.4, linewidth=1)\n",
    "    ax2.text(len(epochs_b)*0.02, threshold + 0.01, f'{threshold:.1%}', fontsize=9, color='red')\n",
    "\n",
    "# Mark grokking moments\n",
    "for r in all_baseline_results:\n",
    "    if r['grokking_epoch'] is not None:\n",
    "        ax2.axvline(x=r['grokking_epoch'], color='green', linestyle=':', alpha=0.5, linewidth=1.5)\n",
    "\n",
    "ax2.set_xlabel('Epoch', fontsize=13)\n",
    "ax2.set_ylabel('Test Accuracy', fontsize=13)\n",
    "ax2.set_title(f'Baseline (Random Init): Test Accuracy (N={NUM_SEEDS} seeds)', fontsize=15, fontweight='bold')\n",
    "ax2.legend(fontsize=11)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_ylim([0, 1.05])\n",
    "\n",
    "# Plot 3: Box plots for each threshold\n",
    "ax3 = fig.add_subplot(gs[2, 0])\n",
    "box_data = []\n",
    "labels = []\n",
    "positions = []\n",
    "pos = 0\n",
    "for i, threshold in enumerate(THRESHOLDS):\n",
    "    t_epochs = [e for e in stats_dict['thresholds'][threshold]['transfer']['values'] if e is not None]\n",
    "    b_epochs = [e for e in stats_dict['thresholds'][threshold]['baseline']['values'] if e is not None]\n",
    "    \n",
    "    if len(t_epochs) > 0:\n",
    "        box_data.append(t_epochs)\n",
    "        labels.append(f\"{threshold:.1%}\\nTransfer\")\n",
    "        positions.append(pos)\n",
    "        pos += 1\n",
    "    \n",
    "    if len(b_epochs) > 0:\n",
    "        box_data.append(b_epochs)\n",
    "        labels.append(f\"{threshold:.1%}\\nBaseline\")\n",
    "        positions.append(pos)\n",
    "        pos += 1\n",
    "    \n",
    "    pos += 0.5  # Gap between thresholds\n",
    "\n",
    "if len(box_data) > 0:\n",
    "    bp = ax3.boxplot(box_data, positions=positions, labels=labels, patch_artist=True, showmeans=True)\n",
    "    # Color boxes\n",
    "    for i, box in enumerate(bp['boxes']):\n",
    "        if 'Transfer' in labels[i]:\n",
    "            box.set_facecolor('lightblue')\n",
    "        else:\n",
    "            box.set_facecolor('lightsalmon')\n",
    "\n",
    "ax3.set_ylabel('Epochs to Threshold', fontsize=12)\n",
    "ax3.set_title('Epochs to Reach Thresholds', fontsize=14, fontweight='bold')\n",
    "ax3.grid(True, alpha=0.3, axis='y')\n",
    "plt.setp(ax3.xaxis.get_majorticklabels(), rotation=45, ha='right', fontsize=9)\n",
    "\n",
    "# Plot 4: Speedup factors\n",
    "ax4 = fig.add_subplot(gs[2, 1])\n",
    "speedups = []\n",
    "speedup_labels = []\n",
    "for threshold in THRESHOLDS:\n",
    "    speedup = stats_dict['thresholds'][threshold]['speedup']\n",
    "    if speedup is not None:\n",
    "        speedups.append(speedup)\n",
    "        speedup_labels.append(f\"{threshold:.1%}\")\n",
    "\n",
    "if len(speedups) > 0:\n",
    "    bars = ax4.bar(range(len(speedups)), speedups, color=['green', 'darkgreen', 'blue', 'darkblue'][:len(speedups)])\n",
    "    ax4.set_xticks(range(len(speedups)))\n",
    "    ax4.set_xticklabels(speedup_labels, fontsize=11)\n",
    "    ax4.set_ylabel('Speedup Factor', fontsize=12)\n",
    "    ax4.set_title('Transfer Learning Speedup', fontsize=14, fontweight='bold')\n",
    "    ax4.grid(True, alpha=0.3, axis='y')\n",
    "    ax4.axhline(y=1, color='red', linestyle='--', linewidth=1, alpha=0.5)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for i, (bar, val) in enumerate(zip(bars, speedups)):\n",
    "        ax4.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,\n",
    "                f'{val:.1f}x', ha='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "# Plot 5: Individual runs overlay (zoomed to 5000 epochs)\n",
    "ax5 = fig.add_subplot(gs[2, 2])\n",
    "zoom = min(5000, len(transfer_mean))\n",
    "for i, r in enumerate(all_transfer_results):\n",
    "    ax5.plot(r['test_accuracies'][:zoom], alpha=0.3, color='blue', linewidth=1)\n",
    "for i, r in enumerate(all_baseline_results):\n",
    "    ax5.plot(r['test_accuracies'][:zoom], alpha=0.3, color='orange', linewidth=1)\n",
    "ax5.plot([], [], color='blue', label='Transfer', linewidth=2)\n",
    "ax5.plot([], [], color='orange', label='Baseline', linewidth=2)\n",
    "for threshold in THRESHOLDS:\n",
    "    ax5.axhline(y=threshold, color='red', linestyle='--', alpha=0.3, linewidth=0.8)\n",
    "ax5.set_xlabel('Epoch', fontsize=12)\n",
    "ax5.set_ylabel('Test Accuracy', fontsize=12)\n",
    "ax5.set_title(f'Individual Runs (First {zoom} Epochs)', fontsize=14, fontweight='bold')\n",
    "ax5.legend(fontsize=11)\n",
    "ax5.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 6: Summary table\n",
    "ax6 = fig.add_subplot(gs[3, :])\n",
    "ax6.axis('off')\n",
    "summary_lines = [\n",
    "    \"COMPREHENSIVE EXPERIMENT SUMMARY\",\n",
    "    \"=\"*70,\n",
    "    f\"Seeds: {SEEDS} (N={NUM_SEEDS})\",\n",
    "    f\"Transfer epochs: {TRANSFER_EPOCHS:,} | Baseline epochs: {BASELINE_EPOCHS:,}\",\n",
    "    \"\",\n",
    "    \"Epochs to Thresholds (mean Â± std):\"\n",
    "]\n",
    "\n",
    "for threshold in THRESHOLDS:\n",
    "    t_stats = stats_dict['thresholds'][threshold]['transfer']\n",
    "    b_stats = stats_dict['thresholds'][threshold]['baseline']\n",
    "    speedup = stats_dict['thresholds'][threshold]['speedup']\n",
    "    \n",
    "    summary_lines.append(f\"  {threshold:.1%}:\")\n",
    "    if t_stats['mean'] is not None:\n",
    "        summary_lines.append(f\"    Transfer: {t_stats['mean']:.0f} Â± {t_stats['std']:.0f} ({t_stats['n_reached']}/{NUM_SEEDS} seeds)\")\n",
    "    else:\n",
    "        summary_lines.append(f\"    Transfer: NOT REACHED\")\n",
    "    \n",
    "    if b_stats['mean'] is not None:\n",
    "        summary_lines.append(f\"    Baseline: {b_stats['mean']:.0f} Â± {b_stats['std']:.0f} ({b_stats['n_reached']}/{NUM_SEEDS} seeds)\")\n",
    "    else:\n",
    "        summary_lines.append(f\"    Baseline: NOT REACHED\")\n",
    "    \n",
    "    if speedup is not None:\n",
    "        summary_lines.append(f\"    Speedup: {speedup:.1f}x\")\n",
    "\n",
    "summary_lines.extend([\n",
    "    \"\",\n",
    "    f\"Final Test Accuracy:\",\n",
    "    f\"  Transfer: {stats_dict['final_accuracy']['transfer']['mean']:.4f} Â± {stats_dict['final_accuracy']['transfer']['std']:.4f}\",\n",
    "    f\"  Baseline: {stats_dict['final_accuracy']['baseline']['mean']:.4f} Â± {stats_dict['final_accuracy']['baseline']['std']:.4f}\"\n",
    "])\n",
    "\n",
    "summary_text = \"\\n\".join(summary_lines)\n",
    "ax6.text(0.5, 0.5, summary_text, fontsize=10, family='monospace',\n",
    "         verticalalignment='center', horizontalalignment='center',\n",
    "         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.3))\n",
    "\n",
    "plt.savefig(f'{EXPERIMENT_DIR}/figures/comprehensive_results.png', dpi=200, bbox_inches='tight')\n",
    "print(f\"\\nâœ“ Saved comprehensive figure\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Complete Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save everything\n",
    "complete_results = {\n",
    "    'config': config_dict,\n",
    "    'transfer_results': all_transfer_results,\n",
    "    'baseline_results': all_baseline_results,\n",
    "    'statistics': stats_dict,\n",
    "    'total_time_hours': total_time / 3600\n",
    "}\n",
    "\n",
    "torch.save(complete_results, f'{EXPERIMENT_DIR}/results/complete_results.pth')\n",
    "print(f\"âœ“ Saved complete results (.pth)\")\n",
    "\n",
    "# Save curves as numpy\n",
    "np.savez(f'{EXPERIMENT_DIR}/results/curves.npz',\n",
    "         transfer_curves=transfer_curves,\n",
    "         baseline_curves_padded=baseline_curves_padded,\n",
    "         seeds=np.array(SEEDS),\n",
    "         thresholds=np.array(THRESHOLDS))\n",
    "print(f\"âœ“ Saved curves (.npz)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"âœ… COMPREHENSIVE EXPERIMENT COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nResults saved to: {EXPERIMENT_DIR}\")\n",
    "print(f\"Total runtime: {total_time/3600:.2f} hours\")\n",
    "print(f\"\\nKey files:\")\n",
    "print(f\"  - figures/comprehensive_results.png (publication-quality figure)\")\n",
    "print(f\"  - results/comprehensive_stats.json (summary statistics)\")\n",
    "print(f\"  - results/complete_results.pth (full experimental data)\")\n",
    "print(f\"  - checkpoints/*.pth ({NUM_SEEDS * 2} model checkpoints)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
