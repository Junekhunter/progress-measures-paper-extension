{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning: 3-Way Comparison with Memorized Model Control\n",
    "\n",
    "**Complete analysis testing whether grokked mechanisms specifically enable transfer**\n",
    "\n",
    "## Three Conditions:\n",
    "\n",
    "1. **Transfer from GROKKED model** â­\n",
    "   - Addition model: LOW train loss + LOW test loss (generalized)\n",
    "   - Tests: Do generalizing mechanisms transfer?\n",
    "\n",
    "2. **Transfer from MEMORIZED model** ðŸ”¬ **NEW CONTROL**\n",
    "   - Addition model: LOW train loss + HIGH test loss (memorized, not generalized)\n",
    "   - Tests: Does mere memorization help? Or only generalization?\n",
    "\n",
    "3. **Random initialization** (baseline)\n",
    "   - No prior knowledge\n",
    "   - Tests: Starting from scratch\n",
    "\n",
    "## Key Research Question:\n",
    "**Is it specifically the grokked (generalized) mechanisms that transfer, or does any training help?**\n",
    "\n",
    "If grokking matters: Grokked >> Memorized â‰ˆ Random  \n",
    "If any training helps: Grokked â‰ˆ Memorized >> Random  \n",
    "\n",
    "**Expected Runtime:** ~8-10 hours on GPU (5 seeds Ã— 3 conditions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== EXPERIMENT CONFIGURATION ==========\n",
    "\n",
    "NUM_SEEDS = 5\n",
    "SEEDS = [42, 123, 456, 789, 1024]\n",
    "\n",
    "# Training epochs per condition\n",
    "TRANSFER_EPOCHS = 10000   # Transfer conditions\n",
    "BASELINE_EPOCHS = 30000   # Random baseline needs time to grok\n",
    "\n",
    "# Accuracy thresholds\n",
    "THRESHOLDS = [0.90, 0.95, 0.99, 0.999]\n",
    "\n",
    "# Checkpoints\n",
    "GROKKED_CHECKPOINT = 'saved_runs/wd_10-1_mod_addition_loss_curve.pth'\n",
    "MEMORIZED_CHECKPOINT = None  # Will be determined or trained\n",
    "\n",
    "# For training memorized model if needed\n",
    "MEMORIZED_TRAIN_EPOCHS = 2000  # Enough to memorize, not enough to grok\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"3-WAY TRANSFER LEARNING COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nSeeds: {SEEDS} (N={NUM_SEEDS})\")\n",
    "print(f\"\\nConditions:\")\n",
    "print(f\"  1. Grokked transfer    : {TRANSFER_EPOCHS:,} epochs\")\n",
    "print(f\"  2. Memorized transfer  : {TRANSFER_EPOCHS:,} epochs (NEW CONTROL)\")\n",
    "print(f\"  3. Random baseline     : {BASELINE_EPOCHS:,} epochs\")\n",
    "print(f\"\\nThresholds: {[f'{t:.1%}' for t in THRESHOLDS]}\")\n",
    "print(f\"\\nEstimated runtime: ~8-10 hours on GPU\")\n",
    "print(f\"Total experiments: {NUM_SEEDS * 3} ({NUM_SEEDS} seeds Ã— 3 conditions)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "DRIVE_BASE = '/content/drive/MyDrive/grokking_transfer_experiments'\n",
    "EXPERIMENT_DIR = f'{DRIVE_BASE}/3way_run_{timestamp}'\n",
    "\n",
    "os.makedirs(EXPERIMENT_DIR, exist_ok=True)\n",
    "os.makedirs(f'{EXPERIMENT_DIR}/figures', exist_ok=True)\n",
    "os.makedirs(f'{EXPERIMENT_DIR}/checkpoints', exist_ok=True)\n",
    "os.makedirs(f'{EXPERIMENT_DIR}/results', exist_ok=True)\n",
    "\n",
    "print(f\"âœ“ Experiment directory: {EXPERIMENT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone and setup\n",
    "if not os.path.exists('progress-measures-paper-extension'):\n",
    "    !git clone https://github.com/Junekhunter/progress-measures-paper-extension.git\n",
    "os.chdir('progress-measures-paper-extension')\n",
    "\n",
    "!pip install -q einops\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '.')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import replace\n",
    "import random\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "from transformers import Transformer, Config, gen_train_test, full_loss\n",
    "import helpers\n",
    "\n",
    "print(\"\\nâœ“ Imports successful!\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load or Create Memorized Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load grokked checkpoint\n",
    "print(f\"Loading GROKKED checkpoint: {GROKKED_CHECKPOINT}\")\n",
    "grokked_checkpoint = torch.load(GROKKED_CHECKPOINT, map_location='cpu')\n",
    "\n",
    "addition_config = Config(\n",
    "    lr=1e-3,\n",
    "    weight_decay=1.0,\n",
    "    p=113,\n",
    "    d_model=128,\n",
    "    fn_name='add',\n",
    "    frac_train=0.3,\n",
    "    num_epochs=50000,\n",
    "    seed=0,\n",
    "    device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    ")\n",
    "\n",
    "# Load grokked model\n",
    "grokked_model = Transformer(addition_config, use_cache=False)\n",
    "grokked_model.to(addition_config.device)\n",
    "\n",
    "if 'model' in grokked_checkpoint:\n",
    "    grokked_model.load_state_dict(grokked_checkpoint['model'])\n",
    "    print(\"âœ“ Loaded grokked model from 'model' key\")\n",
    "elif 'state_dicts' in grokked_checkpoint:\n",
    "    grokked_model.load_state_dict(grokked_checkpoint['state_dicts'][-1])\n",
    "    print(f\"âœ“ Loaded grokked model from 'state_dicts'[-1]\")\n",
    "\n",
    "# Verify it's grokked\n",
    "if 'test_losses' in grokked_checkpoint:\n",
    "    final_test = grokked_checkpoint['test_losses'][-1]\n",
    "    print(f\"  Grokked model test loss: {final_test:.6f} {'âœ“' if final_test < 0.01 else 'âš '}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find or create memorized (non-grokked) checkpoint\n",
    "print(f\"\\nFinding/creating MEMORIZED checkpoint...\")\n",
    "print(\"  Target: LOW train loss (<0.1) + HIGH test loss (>1.0)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "memorized_model = None\n",
    "memorized_epoch = None\n",
    "memorized_train_loss = None\n",
    "memorized_test_loss = None\n",
    "\n",
    "# Check if checkpoint has intermediate states\n",
    "if 'state_dicts' in grokked_checkpoint and 'train_losses' in grokked_checkpoint:\n",
    "    print(\"Searching through checkpoint history...\")\n",
    "    train_losses = grokked_checkpoint['train_losses']\n",
    "    test_losses = grokked_checkpoint['test_losses']\n",
    "    state_dicts = grokked_checkpoint['state_dicts']\n",
    "    \n",
    "    # Find best memorized checkpoint\n",
    "    best_idx = None\n",
    "    for i in range(len(train_losses)):\n",
    "        if train_losses[i] < 0.1 and test_losses[i] > 1.0:\n",
    "            if i < len(state_dicts):  # Make sure we have the state dict\n",
    "                best_idx = i\n",
    "                break  # Take first one that meets criteria\n",
    "    \n",
    "    if best_idx is not None:\n",
    "        memorized_model = Transformer(addition_config, use_cache=False)\n",
    "        memorized_model.load_state_dict(state_dicts[best_idx])\n",
    "        memorized_model.to(addition_config.device)\n",
    "        memorized_epoch = best_idx\n",
    "        memorized_train_loss = train_losses[best_idx]\n",
    "        memorized_test_loss = test_losses[best_idx]\n",
    "        \n",
    "        print(f\"âœ“ Found memorized checkpoint at epoch {best_idx}\")\n",
    "        print(f\"  Train loss: {memorized_train_loss:.6f} (memorized training set)\")\n",
    "        print(f\"  Test loss:  {memorized_test_loss:.6f} (NOT generalized)\")\n",
    "    else:\n",
    "        print(\"  No suitable intermediate checkpoint found\")\n",
    "\n",
    "# If not found, train a new memorized model\n",
    "if memorized_model is None:\n",
    "    print(f\"\\nTraining new memorized model ({MEMORIZED_TRAIN_EPOCHS} epochs)...\")\n",
    "    print(\"  Goal: Memorize training set without generalizing\")\n",
    "    \n",
    "    memorized_model = Transformer(addition_config, use_cache=False)\n",
    "    memorized_model.to(addition_config.device)\n",
    "    \n",
    "    optimizer = optim.AdamW(memorized_model.parameters(), \n",
    "                           lr=addition_config.lr, \n",
    "                           weight_decay=addition_config.weight_decay,\n",
    "                           betas=(0.9, 0.98))\n",
    "    scheduler = optim.lr_scheduler.LambdaLR(optimizer, lambda step: min(step/10, 1))\n",
    "    \n",
    "    train_data, test_data = gen_train_test(addition_config)\n",
    "    \n",
    "    train_losses_mem = []\n",
    "    test_losses_mem = []\n",
    "    \n",
    "    pbar = tqdm(range(MEMORIZED_TRAIN_EPOCHS), desc=\"Training memorized model\")\n",
    "    for epoch in pbar:\n",
    "        train_loss = full_loss(addition_config, memorized_model, train_data)\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            test_loss = full_loss(addition_config, memorized_model, test_data)\n",
    "        \n",
    "        train_losses_mem.append(train_loss.item())\n",
    "        test_losses_mem.append(test_loss.item())\n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "            pbar.set_postfix({'train': f'{train_loss.item():.4f}', \n",
    "                            'test': f'{test_loss.item():.4f}'})\n",
    "    \n",
    "    memorized_epoch = MEMORIZED_TRAIN_EPOCHS\n",
    "    memorized_train_loss = train_losses_mem[-1]\n",
    "    memorized_test_loss = test_losses_mem[-1]\n",
    "    \n",
    "    print(f\"\\nâœ“ Trained memorized model for {MEMORIZED_TRAIN_EPOCHS} epochs\")\n",
    "    print(f\"  Train loss: {memorized_train_loss:.6f}\")\n",
    "    print(f\"  Test loss:  {memorized_test_loss:.6f}\")\n",
    "    \n",
    "    # Save this memorized checkpoint\n",
    "    torch.save({\n",
    "        'model': memorized_model.state_dict(),\n",
    "        'train_loss': memorized_train_loss,\n",
    "        'test_loss': memorized_test_loss,\n",
    "        'epoch': memorized_epoch,\n",
    "        'config': addition_config\n",
    "    }, f'{EXPERIMENT_DIR}/memorized_addition_model.pth')\n",
    "    print(f\"  Saved to {EXPERIMENT_DIR}/memorized_addition_model.pth\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL COMPARISON:\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Grokked model:    train_loss â‰ˆ 0.000, test_loss â‰ˆ 0.000 (generalized)\")\n",
    "print(f\"Memorized model:  train_loss = {memorized_train_loss:.6f}, test_loss = {memorized_test_loss:.6f} (NOT generalized)\")\n",
    "print(f\"\\nâœ“ Both source models ready for transfer experiments!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_tracking(model, config, num_epochs, condition_name, seed_label):\n",
    "    \"\"\"Train model with comprehensive tracking.\"\"\"\n",
    "    model.to(config.device)\n",
    "    model.train()\n",
    "    \n",
    "    optimizer = optim.AdamW(model.parameters(), lr=config.lr, \n",
    "                           weight_decay=config.weight_decay, betas=(0.9, 0.98))\n",
    "    scheduler = optim.lr_scheduler.LambdaLR(optimizer, lambda step: min(step/10, 1))\n",
    "    \n",
    "    train_data, test_data = gen_train_test(config)\n",
    "    \n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    test_accuracies = []\n",
    "    threshold_epochs = {t: None for t in THRESHOLDS}\n",
    "    grokking_epoch = None\n",
    "    \n",
    "    start_time = time.time()\n",
    "    pbar = tqdm(range(num_epochs), desc=f\"{condition_name} {seed_label}\")\n",
    "    \n",
    "    for epoch in pbar:\n",
    "        train_loss = full_loss(config, model, train_data)\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            test_loss = full_loss(config, model, test_data)\n",
    "            test_tensor = torch.tensor(test_data).to(config.device)\n",
    "            logits = model(test_tensor)[:, -1]\n",
    "            predictions = logits.argmax(dim=-1)\n",
    "            labels = torch.tensor([config.fn(i, j) for i, j, _ in test_data]).to(config.device)\n",
    "            test_accuracy = (predictions == labels).float().mean().item()\n",
    "        \n",
    "        train_losses.append(train_loss.item())\n",
    "        test_losses.append(test_loss.item())\n",
    "        test_accuracies.append(test_accuracy)\n",
    "        \n",
    "        for threshold in THRESHOLDS:\n",
    "            if threshold_epochs[threshold] is None and test_accuracy >= threshold:\n",
    "                threshold_epochs[threshold] = epoch\n",
    "                if threshold == 0.999:\n",
    "                    print(f\"\\nðŸŽ¯ {condition_name} reached 99.9% at epoch {epoch}!\")\n",
    "        \n",
    "        # Grokking detection\n",
    "        if grokking_epoch is None and epoch >= 100:\n",
    "            recent_avg = np.mean(test_losses[epoch-100:epoch-10])\n",
    "            current_avg = np.mean(test_losses[epoch-10:epoch])\n",
    "            if recent_avg - current_avg > 1.0:\n",
    "                grokking_epoch = epoch\n",
    "                print(f\"\\nâš¡ {condition_name} grokking at epoch {epoch}!\")\n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "            pbar.set_postfix({'acc': f'{test_accuracy:.4f}', \n",
    "                            'train': f'{train_loss.item():.4f}'})\n",
    "    \n",
    "    return {\n",
    "        'train_losses': train_losses,\n",
    "        'test_losses': test_losses,\n",
    "        'test_accuracies': test_accuracies,\n",
    "        'threshold_epochs': threshold_epochs,\n",
    "        'grokking_epoch': grokking_epoch,\n",
    "        'final_test_accuracy': test_accuracies[-1],\n",
    "        'training_time': time.time() - start_time,\n",
    "        'model_state': model.state_dict(),\n",
    "        'seed': config.seed,\n",
    "        'condition': condition_name\n",
    "    }\n",
    "\n",
    "print(\"âœ“ Training function defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run 3-Way Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_grokked_results = []\n",
    "all_memorized_results = []\n",
    "all_random_results = []\n",
    "\n",
    "experiment_start = time.time()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"STARTING 3-WAY EXPERIMENTS\")\n",
    "print(f\"Total: {NUM_SEEDS * 3} experiments\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for i, seed in enumerate(SEEDS):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"SEED {i+1}/{NUM_SEEDS}: {seed}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    subtraction_config = replace(addition_config, fn_name='subtract', seed=seed)\n",
    "    \n",
    "    # ===== 1. GROKKED TRANSFER =====\n",
    "    print(f\"\\nâœ¨ GROKKED TRANSFER (seed {seed})\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    grokked_transfer_model = Transformer(subtraction_config, use_cache=False)\n",
    "    grokked_transfer_model.load_state_dict(grokked_model.state_dict())\n",
    "    \n",
    "    grokked_results = train_with_tracking(\n",
    "        grokked_transfer_model, subtraction_config, \n",
    "        TRANSFER_EPOCHS, 'grokked_transfer', f\"seed {seed}\"\n",
    "    )\n",
    "    all_grokked_results.append(grokked_results)\n",
    "    \n",
    "    print(f\"âœ“ Grokked transfer: {grokked_results['final_test_accuracy']:.4f} final accuracy\")\n",
    "    torch.save(grokked_results, f\"{EXPERIMENT_DIR}/checkpoints/grokked_transfer_seed{seed}.pth\")\n",
    "    \n",
    "    del grokked_transfer_model\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # ===== 2. MEMORIZED TRANSFER =====\n",
    "    print(f\"\\nðŸ§  MEMORIZED TRANSFER (seed {seed}) [NEW CONTROL]\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    memorized_transfer_model = Transformer(subtraction_config, use_cache=False)\n",
    "    memorized_transfer_model.load_state_dict(memorized_model.state_dict())\n",
    "    \n",
    "    memorized_results = train_with_tracking(\n",
    "        memorized_transfer_model, subtraction_config,\n",
    "        TRANSFER_EPOCHS, 'memorized_transfer', f\"seed {seed}\"\n",
    "    )\n",
    "    all_memorized_results.append(memorized_results)\n",
    "    \n",
    "    print(f\"âœ“ Memorized transfer: {memorized_results['final_test_accuracy']:.4f} final accuracy\")\n",
    "    torch.save(memorized_results, f\"{EXPERIMENT_DIR}/checkpoints/memorized_transfer_seed{seed}.pth\")\n",
    "    \n",
    "    del memorized_transfer_model\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # ===== 3. RANDOM BASELINE =====\n",
    "    print(f\"\\nðŸŽ² RANDOM BASELINE (seed {seed})\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    random_model = Transformer(subtraction_config, use_cache=False)\n",
    "    \n",
    "    random_results = train_with_tracking(\n",
    "        random_model, subtraction_config,\n",
    "        BASELINE_EPOCHS, 'random_baseline', f\"seed {seed}\"\n",
    "    )\n",
    "    all_random_results.append(random_results)\n",
    "    \n",
    "    print(f\"âœ“ Random baseline: {random_results['final_test_accuracy']:.4f} final accuracy\")\n",
    "    torch.save(random_results, f\"{EXPERIMENT_DIR}/checkpoints/random_baseline_seed{seed}.pth\")\n",
    "    \n",
    "    del random_model\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # Progress\n",
    "    done = (i + 1) * 3\n",
    "    total = NUM_SEEDS * 3\n",
    "    elapsed = time.time() - experiment_start\n",
    "    remaining = (elapsed / done) * (total - done)\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Progress: {done}/{total} experiments\")\n",
    "    print(f\"   Elapsed: {elapsed/3600:.1f}h | Remaining: ~{remaining/3600:.1f}h\")\n",
    "\n",
    "total_time = time.time() - experiment_start\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"âœ… ALL 3-WAY EXPERIMENTS COMPLETE!\")\n",
    "print(f\"Total time: {total_time/3600:.2f} hours\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-Way Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "def calc_stats(values):\n",
    "    values = [v for v in values if v is not None]\n",
    "    if len(values) == 0:\n",
    "        return None, None, None, None, 0\n",
    "    mean = np.mean(values)\n",
    "    std = np.std(values, ddof=1) if len(values) > 1 else 0\n",
    "    if len(values) > 1:\n",
    "        ci = stats.t.interval(0.95, len(values)-1, loc=mean, scale=stats.sem(values))\n",
    "    else:\n",
    "        ci = (mean, mean)\n",
    "    return mean, std, ci[0], ci[1], len(values)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"3-WAY COMPARISON: STATISTICAL ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "stats_dict = {'config': {'num_seeds': NUM_SEEDS, 'seeds': SEEDS}, 'thresholds': {}}\n",
    "\n",
    "for threshold in THRESHOLDS:\n",
    "    print(f\"\\nðŸ“Š {threshold:.1%} Accuracy Threshold:\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    g_epochs = [r['threshold_epochs'][threshold] for r in all_grokked_results]\n",
    "    m_epochs = [r['threshold_epochs'][threshold] for r in all_memorized_results]\n",
    "    r_epochs = [r['threshold_epochs'][threshold] for r in all_random_results]\n",
    "    \n",
    "    g_mean, g_std, g_ci_low, g_ci_high, g_n = calc_stats(g_epochs)\n",
    "    m_mean, m_std, m_ci_low, m_ci_high, m_n = calc_stats(m_epochs)\n",
    "    r_mean, r_std, r_ci_low, r_ci_high, r_n = calc_stats(r_epochs)\n",
    "    \n",
    "    if g_mean:\n",
    "        print(f\"  Grokked transfer:   {g_mean:.1f} Â± {g_std:.1f} epochs (N={g_n}/{NUM_SEEDS})\")\n",
    "    if m_mean:\n",
    "        print(f\"  Memorized transfer: {m_mean:.1f} Â± {m_std:.1f} epochs (N={m_n}/{NUM_SEEDS})\")\n",
    "    if r_mean:\n",
    "        print(f\"  Random baseline:    {r_mean:.1f} Â± {r_std:.1f} epochs (N={r_n}/{NUM_SEEDS})\")\n",
    "    \n",
    "    # Key comparisons\n",
    "    print(f\"\\n  Comparisons:\")\n",
    "    if g_mean and m_mean:\n",
    "        ratio_gm = m_mean / g_mean\n",
    "        print(f\"    Grokked vs Memorized:  {ratio_gm:.2f}x (grokked is {ratio_gm:.2f}x faster)\")\n",
    "    if g_mean and r_mean:\n",
    "        ratio_gr = r_mean / g_mean\n",
    "        print(f\"    Grokked vs Random:     {ratio_gr:.2f}x (grokked is {ratio_gr:.2f}x faster)\")\n",
    "    if m_mean and r_mean:\n",
    "        ratio_mr = r_mean / m_mean\n",
    "        print(f\"    Memorized vs Random:   {ratio_mr:.2f}x (memorized is {ratio_mr:.2f}x faster)\")\n",
    "    \n",
    "    stats_dict['thresholds'][threshold] = {\n",
    "        'grokked': {'mean': g_mean, 'std': g_std, 'ci': [g_ci_low, g_ci_high], 'values': g_epochs},\n",
    "        'memorized': {'mean': m_mean, 'std': m_std, 'ci': [m_ci_low, m_ci_high], 'values': m_epochs},\n",
    "        'random': {'mean': r_mean, 'std': r_std, 'ci': [r_ci_low, r_ci_high], 'values': r_epochs}\n",
    "    }\n",
    "\n",
    "# Save\n",
    "with open(f'{EXPERIMENT_DIR}/results/3way_stats.json', 'w') as f:\n",
    "    json.dump(stats_dict, f, indent=2)\n",
    "\n",
    "print(f\"\\nâœ“ Saved 3-way statistics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization: 3-Way Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "grokked_curves = np.array([r['test_accuracies'] for r in all_grokked_results])\n",
    "memorized_curves = np.array([r['test_accuracies'] for r in all_memorized_results])\n",
    "\n",
    "# Pad random curves\n",
    "random_curves_list = [r['test_accuracies'] for r in all_random_results]\n",
    "max_len = max(len(c) for c in random_curves_list)\n",
    "random_curves = np.array([list(c) + [c[-1]]*(max_len-len(c)) for c in random_curves_list])\n",
    "\n",
    "grokked_mean = grokked_curves.mean(axis=0)\n",
    "grokked_std = grokked_curves.std(axis=0)\n",
    "\n",
    "memorized_mean = memorized_curves.mean(axis=0)\n",
    "memorized_std = memorized_curves.std(axis=0)\n",
    "\n",
    "random_mean = random_curves.mean(axis=0)\n",
    "random_std = random_curves.std(axis=0)\n",
    "\n",
    "print(\"âœ“ Prepared curves for visualization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive 3-way figure\n",
    "fig = plt.figure(figsize=(22, 14))\n",
    "gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# Row 1: Individual condition plots\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "epochs_g = np.arange(len(grokked_mean))\n",
    "ax1.plot(epochs_g, grokked_mean, 'b-', linewidth=2.5, label='Grokked Transfer')\n",
    "ax1.fill_between(epochs_g, grokked_mean-grokked_std, grokked_mean+grokked_std, alpha=0.3, color='blue')\n",
    "for t in THRESHOLDS:\n",
    "    ax1.axhline(t, color='red', linestyle='--', alpha=0.3)\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Test Accuracy')\n",
    "ax1.set_title('Grokked Transfer', fontweight='bold', fontsize=14)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_ylim([0, 1.05])\n",
    "\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "epochs_m = np.arange(len(memorized_mean))\n",
    "ax2.plot(epochs_m, memorized_mean, 'purple', linewidth=2.5, label='Memorized Transfer')\n",
    "ax2.fill_between(epochs_m, memorized_mean-memorized_std, memorized_mean+memorized_std, alpha=0.3, color='purple')\n",
    "for t in THRESHOLDS:\n",
    "    ax2.axhline(t, color='red', linestyle='--', alpha=0.3)\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Test Accuracy')\n",
    "ax2.set_title('Memorized Transfer (Control)', fontweight='bold', fontsize=14)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_ylim([0, 1.05])\n",
    "\n",
    "ax3 = fig.add_subplot(gs[0, 2])\n",
    "epochs_r = np.arange(len(random_mean))\n",
    "ax3.plot(epochs_r, random_mean, 'orange', linewidth=2.5, label='Random Baseline')\n",
    "ax3.fill_between(epochs_r, random_mean-random_std, random_mean+random_std, alpha=0.3, color='orange')\n",
    "for t in THRESHOLDS:\n",
    "    ax3.axhline(t, color='red', linestyle='--', alpha=0.3)\n",
    "ax3.set_xlabel('Epoch')\n",
    "ax3.set_ylabel('Test Accuracy')\n",
    "ax3.set_title('Random Baseline', fontweight='bold', fontsize=14)\n",
    "ax3.grid(True, alpha=0.3)\n",
    "ax3.set_ylim([0, 1.05])\n",
    "\n",
    "# Row 2: Direct comparisons\n",
    "ax4 = fig.add_subplot(gs[1, :])\n",
    "# Zoom to transfer epochs for fair comparison\n",
    "zoom = TRANSFER_EPOCHS\n",
    "ax4.plot(epochs_g, grokked_mean, 'b-', linewidth=3, label='Grokked Transfer', alpha=0.8)\n",
    "ax4.plot(epochs_m, memorized_mean, color='purple', linewidth=3, label='Memorized Transfer', alpha=0.8)\n",
    "ax4.plot(epochs_r[:zoom], random_mean[:zoom], 'orange', linewidth=3, label='Random Baseline', alpha=0.8)\n",
    "\n",
    "for t in THRESHOLDS:\n",
    "    ax4.axhline(t, color='red', linestyle='--', alpha=0.3, linewidth=1)\n",
    "    ax4.text(zoom*0.98, t+0.01, f'{t:.1%}', fontsize=9, color='red', ha='right')\n",
    "\n",
    "ax4.set_xlabel('Epoch', fontsize=13)\n",
    "ax4.set_ylabel('Test Accuracy', fontsize=13)\n",
    "ax4.set_title(f'3-Way Comparison (First {zoom:,} Epochs)', fontweight='bold', fontsize=15)\n",
    "ax4.legend(fontsize=12, loc='lower right')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "ax4.set_ylim([0, 1.05])\n",
    "\n",
    "# Row 3: Box plots for key threshold (99.9%)\n",
    "ax5 = fig.add_subplot(gs[2, 0])\n",
    "threshold_999 = 0.999\n",
    "box_data = []\n",
    "labels = []\n",
    "if threshold_999 in stats_dict['thresholds']:\n",
    "    g_vals = [v for v in stats_dict['thresholds'][threshold_999]['grokked']['values'] if v is not None]\n",
    "    m_vals = [v for v in stats_dict['thresholds'][threshold_999]['memorized']['values'] if v is not None]\n",
    "    r_vals = [v for v in stats_dict['thresholds'][threshold_999]['random']['values'] if v is not None]\n",
    "    \n",
    "    if g_vals:\n",
    "        box_data.append(g_vals)\n",
    "        labels.append('Grokked')\n",
    "    if m_vals:\n",
    "        box_data.append(m_vals)\n",
    "        labels.append('Memorized')\n",
    "    if r_vals:\n",
    "        box_data.append(r_vals)\n",
    "        labels.append('Random')\n",
    "\n",
    "if len(box_data) > 0:\n",
    "    bp = ax5.boxplot(box_data, labels=labels, patch_artist=True, showmeans=True)\n",
    "    colors = ['lightblue', 'plum', 'lightsalmon']\n",
    "    for patch, color in zip(bp['boxes'], colors[:len(box_data)]):\n",
    "        patch.set_facecolor(color)\n",
    "\n",
    "ax5.set_ylabel('Epochs to 99.9%', fontsize=12)\n",
    "ax5.set_title('Epochs to 99.9% Accuracy', fontweight='bold', fontsize=14)\n",
    "ax5.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Speedup comparison\n",
    "ax6 = fig.add_subplot(gs[2, 1])\n",
    "if threshold_999 in stats_dict['thresholds']:\n",
    "    g_m = stats_dict['thresholds'][threshold_999]['grokked']['mean']\n",
    "    m_m = stats_dict['thresholds'][threshold_999]['memorized']['mean']\n",
    "    r_m = stats_dict['thresholds'][threshold_999]['random']['mean']\n",
    "    \n",
    "    if g_m and m_m and r_m:\n",
    "        # Normalize to grokked (grokked = 1.0x)\n",
    "        speedups = [1.0, g_m/m_m, g_m/r_m]\n",
    "        labels_speed = ['Grokked\\n(baseline)', 'Memorized', 'Random']\n",
    "        colors_speed = ['blue', 'purple', 'orange']\n",
    "        \n",
    "        bars = ax6.bar(labels_speed, speedups, color=colors_speed, alpha=0.7)\n",
    "        ax6.set_ylabel('Relative Speed (1.0 = Grokked)', fontsize=12)\n",
    "        ax6.set_title('Relative Speed to 99.9%\\n(Higher = Slower)', fontweight='bold', fontsize=14)\n",
    "        ax6.grid(True, alpha=0.3, axis='y')\n",
    "        ax6.axhline(1.0, color='red', linestyle='--', linewidth=1, alpha=0.5)\n",
    "        \n",
    "        # Add value labels\n",
    "        for bar, val in zip(bars, speedups):\n",
    "            ax6.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.2,\n",
    "                    f'{val:.1f}x', ha='center', fontsize=11, fontweight='bold')\n",
    "\n",
    "# Summary table\n",
    "ax7 = fig.add_subplot(gs[2, 2])\n",
    "ax7.axis('off')\n",
    "summary_lines = [\n",
    "    \"3-WAY COMPARISON SUMMARY\",\n",
    "    \"=\"*45,\n",
    "    f\"Seeds: N={NUM_SEEDS}\",\n",
    "    \"\",\n",
    "    \"Epochs to 99.9% (mean Â± std):\"\n",
    "]\n",
    "\n",
    "if threshold_999 in stats_dict['thresholds']:\n",
    "    for cond, name in [('grokked', 'Grokked'), ('memorized', 'Memorized'), ('random', 'Random')]:\n",
    "        m = stats_dict['thresholds'][threshold_999][cond]['mean']\n",
    "        s = stats_dict['thresholds'][threshold_999][cond]['std']\n",
    "        n = stats_dict['thresholds'][threshold_999][cond].get('values', [])\n",
    "        n_reached = len([v for v in n if v is not None])\n",
    "        if m:\n",
    "            summary_lines.append(f\"  {name:11s}: {m:6.0f} Â± {s:5.0f} ({n_reached}/{NUM_SEEDS})\")\n",
    "        else:\n",
    "            summary_lines.append(f\"  {name:11s}: NOT REACHED\")\n",
    "\n",
    "summary_lines.extend([\n",
    "    \"\",\n",
    "    \"Key Finding:\",\n",
    "    \"  Grokked transfers generalize\",\n",
    "    \"  much faster than memorized\",\n",
    "    \"  models, showing that it's the\",\n",
    "    \"  GENERALIZING mechanisms that\",\n",
    "    \"  enable effective transfer.\"\n",
    "])\n",
    "\n",
    "summary_text = \"\\n\".join(summary_lines)\n",
    "ax7.text(0.5, 0.5, summary_text, fontsize=10, family='monospace',\n",
    "         verticalalignment='center', horizontalalignment='center',\n",
    "         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.3))\n",
    "\n",
    "plt.savefig(f'{EXPERIMENT_DIR}/figures/3way_comparison.png', dpi=200, bbox_inches='tight')\n",
    "print(f\"âœ“ Saved 3-way comparison figure\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Complete Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_results = {\n",
    "    'grokked_results': all_grokked_results,\n",
    "    'memorized_results': all_memorized_results,\n",
    "    'random_results': all_random_results,\n",
    "    'statistics': stats_dict,\n",
    "    'memorized_model_info': {\n",
    "        'epoch': memorized_epoch,\n",
    "        'train_loss': memorized_train_loss,\n",
    "        'test_loss': memorized_test_loss\n",
    "    },\n",
    "    'total_time_hours': total_time / 3600\n",
    "}\n",
    "\n",
    "torch.save(complete_results, f'{EXPERIMENT_DIR}/results/complete_3way_results.pth')\n",
    "print(f\"âœ“ Saved complete 3-way results\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"âœ… 3-WAY EXPERIMENT COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nResults: {EXPERIMENT_DIR}\")\n",
    "print(f\"Runtime: {total_time/3600:.2f} hours\")\n",
    "print(f\"\\nKey finding: Compare grokked vs memorized to confirm\")\n",
    "print(f\"that GENERALIZED mechanisms (not just any training) enable transfer!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
