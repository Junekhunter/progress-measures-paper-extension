{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comprehensive 5-Seed Transfer Learning Analysis\n",
    "\n",
    "**Complete analysis across all 5 seeds (42, 7, 99, 314, 123)**\n",
    "\n",
    "This notebook performs:\n",
    "1. Addition retention testing (catastrophic forgetting)\n",
    "2. Circuit analysis (neuron specialization, frequency usage)\n",
    "3. Learning dynamics comparison\n",
    "4. Statistical aggregation across 4 normal seeds (42, 7, 99, 314)\n",
    "5. Outlier analysis for seed 123\n",
    "\n",
    "**Goal**: Determine if transfer learning from grokked models provides:\n",
    "- Multi-task retention (addition knowledge)\n",
    "- Faster convergence on new tasks\n",
    "- More generalizable circuits\n",
    "- Different behavior in outlier cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive and navigate to repo\n",
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "if not os.path.exists('progress-measures-paper-extension'):\n",
    "    !git clone https://github.com/Junekhunter/progress-measures-paper-extension.git\n",
    "\n",
    "os.chdir('progress-measures-paper-extension')\n",
    "!pip install -q einops\n",
    "\n",
    "print(f\"Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys\n",
    "sys.path.insert(0, '.')\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from dataclasses import replace\n",
    "from scipy.stats import spearmanr, ttest_ind\n",
    "from collections import defaultdict\n",
    "\n",
    "from transformers import Transformer, Config, gen_train_test\n",
    "import helpers\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "print(\"\u2713 Imports successful\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "EXPERIMENT_DIR = input(\"Enter your 3-way experiment directory path: \")\n",
    "SEEDS = [42, 7, 99, 314, 123]  # Last one is potential outlier\n",
    "NORMAL_SEEDS = [42, 7, 99, 314]  # Normal seeds for aggregation\n",
    "OUTLIER_SEED = 123\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"Analyzing seeds: {SEEDS}\")\n",
    "print(f\"Normal seeds for aggregation: {NORMAL_SEEDS}\")\n",
    "print(f\"Outlier seed for separate analysis: {OUTLIER_SEED}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Multi-Seed Addition Retention Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load source grokked addition model (used for all seeds)\n",
    "print(\"Loading source grokked addition model...\")\n",
    "addition_checkpoint = torch.load('saved_runs/wd_10-1_mod_addition_loss_curve.pth', map_location='cpu')\n",
    "\n",
    "addition_config = Config(\n",
    "    lr=1e-3,\n",
    "    weight_decay=1.0,\n",
    "    p=113,\n",
    "    d_model=128,\n",
    "    fn_name='add',\n",
    "    frac_train=0.3,\n",
    "    seed=0,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "grokked_addition_model = Transformer(addition_config, use_cache=False)\n",
    "if 'model' in addition_checkpoint:\n",
    "    grokked_addition_model.load_state_dict(addition_checkpoint['model'])\n",
    "else:\n",
    "    grokked_addition_model.load_state_dict(addition_checkpoint['state_dicts'][-1])\n",
    "grokked_addition_model.to(device)\n",
    "grokked_addition_model.eval()\n",
    "\n",
    "# Generate addition test data\n",
    "addition_train, addition_test = gen_train_test(addition_config)\n",
    "addition_train_tensor = torch.tensor(addition_train).to(device)\n",
    "addition_test_tensor = torch.tensor(addition_test).to(device)\n",
    "\n",
    "print(f\"\u2713 Source model loaded\")\n",
    "print(f\"\u2713 Addition dataset: {len(addition_train)} train, {len(addition_test)} test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_on_addition(model, data, config):\n",
    "    \"\"\"Evaluate model on addition task.\"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(data)\n",
    "        predictions = logits[:, -1, :config.p].argmax(dim=-1)\n",
    "    \n",
    "    targets = torch.tensor([config.fn(a, b) for a, b, _ in data]).to(config.device)\n",
    "    accuracy = (predictions == targets).float().mean().item()\n",
    "    \n",
    "    return accuracy, predictions.cpu().numpy()\n",
    "\n",
    "print(\"\u2713 Evaluation function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all models across all seeds\n",
    "print(\"=\"*80)\n",
    "print(\"LOADING ALL MODELS (5 SEEDS \u00d7 3 CONDITIONS = 15 MODELS)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "all_models = defaultdict(dict)  # {seed: {condition: model_data}}\n",
    "conditions = ['grokked_transfer', 'memorized_transfer', 'random_baseline']\n",
    "\n",
    "for seed in SEEDS:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"SEED {seed}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    subtraction_config = replace(addition_config, fn_name='subtract', seed=seed)\n",
    "    \n",
    "    for condition in conditions:\n",
    "        print(f\"  Loading {condition}...\")\n",
    "        \n",
    "        checkpoint_path = f'{EXPERIMENT_DIR}/checkpoints/{condition}_seed{seed}.pth'\n",
    "        checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
    "        \n",
    "        # Verify checkpoint structure\n",
    "        if 'model_state' not in checkpoint:\n",
    "            raise ValueError(f\"Checkpoint missing 'model_state'! Keys: {list(checkpoint.keys())}\")\n",
    "        \n",
    "        # Create and load model\n",
    "        model = Transformer(subtraction_config, use_cache=False)\n",
    "        model.load_state_dict(checkpoint['model_state'], strict=True)\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        \n",
    "        # Verify model loaded by checking first parameter\n",
    "        first_param = next(model.parameters()).data.flatten()[:10]\n",
    "        param_sum = first_param.sum().item()\n",
    "        \n",
    "        all_models[seed][condition] = {\n",
    "            'model': model,\n",
    "            'checkpoint': checkpoint,\n",
    "            'subtraction_accuracy': checkpoint['final_test_accuracy'],\n",
    "            'epochs_to_999': checkpoint['threshold_epochs'].get(0.999),\n",
    "            'param_checksum': param_sum\n",
    "        }\n",
    "        \n",
    "        print(f\"    Subtraction acc: {checkpoint['final_test_accuracy']:.4f}\")\n",
    "        print(f\"    Epochs to 99.9%: {checkpoint['threshold_epochs'].get(0.999, 'N/A')}\")\n",
    "        print(f\"    Param checksum: {param_sum:.4f}\")\n",
    "\n",
    "print(f\"\\n\u2713 All {len(SEEDS) * len(conditions)} models loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Check: Verify Models Are Actually Doing Subtraction\n",
    "\n",
    "**Critical validation**: Ensure models aren't just still doing addition when tested on subtraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check: Verify models do subtraction, not addition\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SANITY CHECK: Are models actually doing SUBTRACTION?\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def test_operation(model, config, test_data):\n",
    "    \"\"\"Test if model predictions match a given operation.\"\"\"\n",
    "    model.eval()\n",
    "    test_tensor = torch.tensor(test_data).to(config.device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits = model(test_tensor)\n",
    "        predictions = logits[:, -1, :config.p].argmax(dim=-1).cpu().numpy()\n",
    "    \n",
    "    # Test against different operations\n",
    "    add_targets = np.array([(a + b) % config.p for a, b, _ in test_data])\n",
    "    sub_targets = np.array([(a - b) % config.p for a, b, _ in test_data])\n",
    "    \n",
    "    add_acc = np.mean(predictions == add_targets)\n",
    "    sub_acc = np.mean(predictions == sub_targets)\n",
    "    \n",
    "    return {\n",
    "        'predictions': predictions,\n",
    "        'addition_accuracy': add_acc,\n",
    "        'subtraction_accuracy': sub_acc\n",
    "    }\n",
    "\n",
    "# Test each condition on subtraction data for one representative seed\n",
    "test_seed = SEEDS[0]  # Use first seed as representative\n",
    "print(f\"\\nTesting seed {test_seed}:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Generate subtraction test data\n",
    "subtraction_config = replace(addition_config, fn_name='subtract', seed=test_seed)\n",
    "_, sub_test = gen_train_test(subtraction_config)\n",
    "\n",
    "for condition in conditions:\n",
    "    model = all_models[test_seed][condition]['model']\n",
    "    \n",
    "    results = test_operation(model, subtraction_config, sub_test)\n",
    "    \n",
    "    print(f\"\\n{condition.replace('_', ' ').title()}:\")\n",
    "    print(f\"  When tested on SUBTRACTION inputs:\")\n",
    "    print(f\"    Accuracy if doing ADDITION:    {results['addition_accuracy']*100:.2f}%\")\n",
    "    print(f\"    Accuracy if doing SUBTRACTION: {results['subtraction_accuracy']*100:.2f}%\")\n",
    "    \n",
    "    # Determine what operation the model is actually doing\n",
    "    if results['subtraction_accuracy'] > 0.95:\n",
    "        print(f\"    \u2713 Model is doing SUBTRACTION (as expected)\")\n",
    "    elif results['addition_accuracy'] > 0.95:\n",
    "        print(f\"    WARNING: Model is still doing ADDITION!\")\n",
    "    elif results['subtraction_accuracy'] > results['addition_accuracy'] + 0.1:\n",
    "        print(f\"    \u2192 Model is mostly doing SUBTRACTION\")\n",
    "    elif results['addition_accuracy'] > results['subtraction_accuracy'] + 0.1:\n",
    "        print(f\"    WARNING: Model is mostly doing ADDITION\")\n",
    "    else:\n",
    "        print(f\"    ? Model is doing neither (random/other pattern)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SANITY CHECK COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nIf all models show >95% subtraction accuracy, they are correctly\")\n",
    "print(\"learning subtraction, NOT just memorizing addition patterns.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test all models on addition\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TESTING ALL MODELS ON ADDITION TASK\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "addition_results = defaultdict(lambda: defaultdict(dict))  # {seed: {condition: results}}\n",
    "\n",
    "for seed in SEEDS:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"SEED {seed}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    for condition in conditions:\n",
    "        model = all_models[seed][condition]['model']\n",
    "        \n",
    "        # Test on addition\n",
    "        test_acc, test_preds = evaluate_on_addition(model, addition_test_tensor, addition_config)\n",
    "        train_acc, _ = evaluate_on_addition(model, addition_train_tensor, addition_config)\n",
    "        \n",
    "        addition_results[seed][condition] = {\n",
    "            'train_acc': train_acc,\n",
    "            'test_acc': test_acc,\n",
    "            'predictions': test_preds,\n",
    "            'subtraction_acc': all_models[seed][condition]['subtraction_accuracy']\n",
    "        }\n",
    "        \n",
    "        print(f\"  {condition}:\")\n",
    "        print(f\"    Addition test:  {test_acc*100:.2f}%\")\n",
    "        print(f\"    Subtraction:    {all_models[seed][condition]['subtraction_accuracy']*100:.2f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\u2713 ALL MODELS TESTED\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check prediction agreement within each seed\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PREDICTION AGREEMENT ANALYSIS (PER SEED)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "prediction_agreements = defaultdict(dict)\n",
    "\n",
    "for seed in SEEDS:\n",
    "    print(f\"\\nSeed {seed}:\")\n",
    "    \n",
    "    grok_preds = addition_results[seed]['grokked_transfer']['predictions']\n",
    "    mem_preds = addition_results[seed]['memorized_transfer']['predictions']\n",
    "    rand_preds = addition_results[seed]['random_baseline']['predictions']\n",
    "    \n",
    "    grok_vs_mem = np.mean(grok_preds == mem_preds)\n",
    "    grok_vs_rand = np.mean(grok_preds == rand_preds)\n",
    "    mem_vs_rand = np.mean(mem_preds == rand_preds)\n",
    "    \n",
    "    prediction_agreements[seed] = {\n",
    "        'grok_vs_mem': grok_vs_mem,\n",
    "        'grok_vs_rand': grok_vs_rand,\n",
    "        'mem_vs_rand': mem_vs_rand\n",
    "    }\n",
    "    \n",
    "    print(f\"  Grokked vs Memorized: {grok_vs_mem*100:.1f}%\")\n",
    "    print(f\"  Grokked vs Random:    {grok_vs_rand*100:.1f}%\")\n",
    "    print(f\"  Memorized vs Random:  {mem_vs_rand*100:.1f}%\")\n",
    "    \n",
    "    if grok_vs_mem > 0.95 and grok_vs_rand > 0.95:\n",
    "        print(f\"  \u26a0\ufe0f  All models producing nearly identical predictions!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Circuit Analysis (Multi-Seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Fourier coefficients for all models\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FOURIER FREQUENCY ANALYSIS (ALL SEEDS)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "fourier_results = defaultdict(lambda: defaultdict(dict))\n",
    "\n",
    "for seed in SEEDS:\n",
    "    print(f\"\\nSeed {seed}:\")\n",
    "    \n",
    "    for condition in conditions:\n",
    "        model = all_models[seed][condition]['model']\n",
    "        \n",
    "        # Compute Fourier coefficients\n",
    "        W_E = model.embed.W_E.data  # [d_model, d_vocab]\n",
    "        W_U = model.unembed.W_U.data  # [d_model, d_vocab]\n",
    "        \n",
    "        # Compute neuron frequency spectrum\n",
    "        neuron_freqs = []\n",
    "        neuron_explained_vars = []\n",
    "        \n",
    "        for neuron_idx in range(W_E.shape[0]):\n",
    "            # Get embedding and unembedding weights for this neuron\n",
    "            w_e = W_E[neuron_idx, :].cpu().numpy()  # [d_vocab]\n",
    "            w_u = W_U[neuron_idx, :].cpu().numpy()  # [d_vocab]\n",
    "            \n",
    "            # Compute Fourier transform\n",
    "            fft_e = np.fft.fft(w_e)\n",
    "            fft_u = np.fft.fft(w_u)\n",
    "            \n",
    "            # Compute power spectrum\n",
    "            power = np.abs(fft_e * fft_u)\n",
    "            \n",
    "            # Find dominant frequency\n",
    "            dominant_freq = np.argmax(power)\n",
    "            \n",
    "            # Compute fraction of variance explained by dominant frequency\n",
    "            total_power = np.sum(power)\n",
    "            if total_power > 0:\n",
    "                frac_explained = power[dominant_freq] / total_power\n",
    "            else:\n",
    "                frac_explained = 0\n",
    "            \n",
    "            neuron_freqs.append(dominant_freq)\n",
    "            neuron_explained_vars.append(frac_explained)\n",
    "        \n",
    "        neuron_freqs = np.array(neuron_freqs)\n",
    "        neuron_explained_vars = np.array(neuron_explained_vars)\n",
    "        \n",
    "        # Get unique frequencies\n",
    "        unique_freqs = np.unique(neuron_freqs)\n",
    "        \n",
    "        fourier_results[seed][condition] = {\n",
    "            'neuron_freqs': neuron_freqs,\n",
    "            'explained_vars': neuron_explained_vars,\n",
    "            'unique_freqs': unique_freqs,\n",
    "            'mean_explained': neuron_explained_vars.mean(),\n",
    "            'num_specialized': np.sum(neuron_explained_vars > 0.5)\n",
    "        }\n",
    "        \n",
    "        print(f\"  {condition}:\")\n",
    "        print(f\"    Unique frequencies: {len(unique_freqs)}\")\n",
    "        print(f\"    Mean specialization: {neuron_explained_vars.mean():.3f}\")\n",
    "        print(f\"    Neurons >50% specialized: {np.sum(neuron_explained_vars > 0.5)}/{len(neuron_explained_vars)}\")\n",
    "\n",
    "print(\"\\n\u2713 Fourier analysis complete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Statistical Aggregation (Normal Seeds vs Outlier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate statistics across normal seeds\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STATISTICAL AGGREGATION: NORMAL SEEDS\")\n",
    "print(f\"Seeds: {NORMAL_SEEDS}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "normal_stats = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "for seed in NORMAL_SEEDS:\n",
    "    for condition in conditions:\n",
    "        # Addition retention\n",
    "        normal_stats[condition]['addition_test_acc'].append(\n",
    "            addition_results[seed][condition]['test_acc']\n",
    "        )\n",
    "        \n",
    "        # Subtraction performance\n",
    "        normal_stats[condition]['subtraction_acc'].append(\n",
    "            addition_results[seed][condition]['subtraction_acc']\n",
    "        )\n",
    "        \n",
    "        # Circuit specialization\n",
    "        normal_stats[condition]['mean_specialization'].append(\n",
    "            fourier_results[seed][condition]['mean_explained']\n",
    "        )\n",
    "        \n",
    "        # Convergence speed\n",
    "        epochs_999 = all_models[seed][condition]['epochs_to_999']\n",
    "        if epochs_999 is not None:\n",
    "            normal_stats[condition]['epochs_to_999'].append(epochs_999)\n",
    "\n",
    "# Print aggregated statistics\n",
    "print(\"\\nAGGREGATED STATISTICS (mean \u00b1 std):\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for condition in conditions:\n",
    "    print(f\"\\n{condition.upper().replace('_', ' ')}:\")\n",
    "    \n",
    "    # Addition retention\n",
    "    add_accs = normal_stats[condition]['addition_test_acc']\n",
    "    print(f\"  Addition test accuracy: {np.mean(add_accs)*100:.2f}% \u00b1 {np.std(add_accs)*100:.2f}%\")\n",
    "    \n",
    "    # Subtraction\n",
    "    sub_accs = normal_stats[condition]['subtraction_acc']\n",
    "    print(f\"  Subtraction accuracy:   {np.mean(sub_accs)*100:.2f}% \u00b1 {np.std(sub_accs)*100:.2f}%\")\n",
    "    \n",
    "    # Specialization\n",
    "    specs = normal_stats[condition]['mean_specialization']\n",
    "    print(f\"  Mean specialization:    {np.mean(specs):.3f} \u00b1 {np.std(specs):.3f}\")\n",
    "    \n",
    "    # Convergence\n",
    "    epochs = normal_stats[condition]['epochs_to_999']\n",
    "    if epochs:\n",
    "        print(f\"  Epochs to 99.9%:        {np.mean(epochs):.0f} \u00b1 {np.std(epochs):.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare outlier to normal seeds\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"OUTLIER ANALYSIS: SEED {OUTLIER_SEED} vs NORMAL SEEDS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "outlier_comparison = {}\n",
    "\n",
    "for condition in conditions:\n",
    "    print(f\"\\n{condition.upper().replace('_', ' ')}:\")\n",
    "    \n",
    "    outlier_comparison[condition] = {}\n",
    "    \n",
    "    # Addition retention\n",
    "    outlier_add = addition_results[OUTLIER_SEED][condition]['test_acc']\n",
    "    normal_add_mean = np.mean(normal_stats[condition]['addition_test_acc'])\n",
    "    normal_add_std = np.std(normal_stats[condition]['addition_test_acc'])\n",
    "    z_score_add = (outlier_add - normal_add_mean) / (normal_add_std + 1e-8)\n",
    "    \n",
    "    print(f\"  Addition test accuracy:\")\n",
    "    print(f\"    Normal: {normal_add_mean*100:.2f}% \u00b1 {normal_add_std*100:.2f}%\")\n",
    "    print(f\"    Outlier: {outlier_add*100:.2f}% (z={z_score_add:.2f})\")\n",
    "    \n",
    "    outlier_comparison[condition]['addition_zscore'] = z_score_add\n",
    "    \n",
    "    # Specialization\n",
    "    outlier_spec = fourier_results[OUTLIER_SEED][condition]['mean_explained']\n",
    "    normal_spec_mean = np.mean(normal_stats[condition]['mean_specialization'])\n",
    "    normal_spec_std = np.std(normal_stats[condition]['mean_specialization'])\n",
    "    z_score_spec = (outlier_spec - normal_spec_mean) / (normal_spec_std + 1e-8)\n",
    "    \n",
    "    print(f\"  Mean specialization:\")\n",
    "    print(f\"    Normal: {normal_spec_mean:.3f} \u00b1 {normal_spec_std:.3f}\")\n",
    "    print(f\"    Outlier: {outlier_spec:.3f} (z={z_score_spec:.2f})\")\n",
    "    \n",
    "    outlier_comparison[condition]['specialization_zscore'] = z_score_spec\n",
    "    \n",
    "    # Convergence\n",
    "    outlier_epochs = all_models[OUTLIER_SEED][condition]['epochs_to_999']\n",
    "    if outlier_epochs is not None and normal_stats[condition]['epochs_to_999']:\n",
    "        normal_epochs_mean = np.mean(normal_stats[condition]['epochs_to_999'])\n",
    "        normal_epochs_std = np.std(normal_stats[condition]['epochs_to_999'])\n",
    "        z_score_epochs = (outlier_epochs - normal_epochs_mean) / (normal_epochs_std + 1e-8)\n",
    "        \n",
    "        print(f\"  Epochs to 99.9%:\")\n",
    "        print(f\"    Normal: {normal_epochs_mean:.0f} \u00b1 {normal_epochs_std:.0f}\")\n",
    "        print(f\"    Outlier: {outlier_epochs} (z={z_score_epochs:.2f})\")\n",
    "        \n",
    "        outlier_comparison[condition]['epochs_zscore'] = z_score_epochs\n",
    "        \n",
    "        if abs(z_score_epochs) > 2:\n",
    "            print(f\"    \u26a0\ufe0f  SIGNIFICANT OUTLIER (|z| > 2)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"OUTLIER SUMMARY:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "is_outlier = False\n",
    "for condition in conditions:\n",
    "    for metric, zscore in outlier_comparison[condition].items():\n",
    "        if abs(zscore) > 2:\n",
    "            print(f\"\u2713 {condition} - {metric}: z={zscore:.2f} (OUTLIER)\")\n",
    "            is_outlier = True\n",
    "\n",
    "if not is_outlier:\n",
    "    print(\"\u2192 Seed 123 is NOT a significant outlier (all |z| < 2)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualization\n",
    "fig = plt.figure(figsize=(20, 12))\n",
    "gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# Plot 1: Addition retention across seeds\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "x_pos = np.arange(len(SEEDS))\n",
    "width = 0.25\n",
    "\n",
    "for i, condition in enumerate(conditions):\n",
    "    accs = [addition_results[seed][condition]['test_acc'] * 100 for seed in SEEDS]\n",
    "    ax1.bar(x_pos + i*width, accs, width, \n",
    "            label=condition.replace('_', ' ').title(),\n",
    "            alpha=0.8)\n",
    "\n",
    "ax1.set_xlabel('Seed')\n",
    "ax1.set_ylabel('Addition Test Accuracy (%)')\n",
    "ax1.set_title('Addition Retention Across Seeds')\n",
    "ax1.set_xticks(x_pos + width)\n",
    "ax1.set_xticklabels(SEEDS)\n",
    "ax1.axhline(100/113, color='red', linestyle='--', alpha=0.5, label='Random chance')\n",
    "ax1.legend(fontsize=8)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Convergence speed\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "\n",
    "for i, condition in enumerate(conditions):\n",
    "    epochs = [all_models[seed][condition]['epochs_to_999'] for seed in SEEDS \n",
    "              if all_models[seed][condition]['epochs_to_999'] is not None]\n",
    "    if epochs:\n",
    "        ax2.bar(i, np.mean(epochs), yerr=np.std(epochs), \n",
    "                label=condition.replace('_', ' ').title(),\n",
    "                alpha=0.8, capsize=5)\n",
    "\n",
    "ax2.set_ylabel('Epochs to 99.9% Accuracy')\n",
    "ax2.set_title('Convergence Speed (Mean \u00b1 Std)')\n",
    "ax2.set_xticks(range(len(conditions)))\n",
    "ax2.set_xticklabels([c.replace('_', '\\n').title() for c in conditions], fontsize=9)\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Plot 3: Neuron specialization\n",
    "ax3 = fig.add_subplot(gs[0, 2])\n",
    "\n",
    "for i, condition in enumerate(conditions):\n",
    "    specs = [fourier_results[seed][condition]['mean_explained'] for seed in SEEDS]\n",
    "    ax3.bar(i, np.mean(specs), yerr=np.std(specs),\n",
    "            label=condition.replace('_', ' ').title(),\n",
    "            alpha=0.8, capsize=5)\n",
    "\n",
    "ax3.set_ylabel('Mean Neuron Specialization')\n",
    "ax3.set_title('Circuit Specialization (Mean \u00b1 Std)')\n",
    "ax3.set_xticks(range(len(conditions)))\n",
    "ax3.set_xticklabels([c.replace('_', '\\n').title() for c in conditions], fontsize=9)\n",
    "ax3.set_ylim([0, 1])\n",
    "ax3.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Plot 4: Prediction agreement heatmap\n",
    "ax4 = fig.add_subplot(gs[1, :])\n",
    "\n",
    "agreement_matrix = np.zeros((len(SEEDS), 3))  # 3 comparisons per seed\n",
    "for i, seed in enumerate(SEEDS):\n",
    "    agreement_matrix[i, 0] = prediction_agreements[seed]['grok_vs_mem']\n",
    "    agreement_matrix[i, 1] = prediction_agreements[seed]['grok_vs_rand']\n",
    "    agreement_matrix[i, 2] = prediction_agreements[seed]['mem_vs_rand']\n",
    "\n",
    "im = ax4.imshow(agreement_matrix.T, aspect='auto', cmap='RdYlGn', vmin=0, vmax=1)\n",
    "ax4.set_yticks(range(3))\n",
    "ax4.set_yticklabels(['Grok vs Mem', 'Grok vs Rand', 'Mem vs Rand'])\n",
    "ax4.set_xticks(range(len(SEEDS)))\n",
    "ax4.set_xticklabels(SEEDS)\n",
    "ax4.set_xlabel('Seed')\n",
    "ax4.set_title('Prediction Agreement on Addition Task (Fraction Identical)')\n",
    "\n",
    "# Add text annotations\n",
    "for i in range(len(SEEDS)):\n",
    "    for j in range(3):\n",
    "        text = ax4.text(i, j, f'{agreement_matrix[i, j]:.2f}',\n",
    "                       ha=\"center\", va=\"center\", color=\"black\", fontsize=9)\n",
    "\n",
    "plt.colorbar(im, ax=ax4, label='Agreement')\n",
    "\n",
    "# Plot 5: Normal vs Outlier comparison\n",
    "ax5 = fig.add_subplot(gs[2, 0])\n",
    "\n",
    "metrics = ['Addition\\nRetention', 'Specialization', 'Convergence\\nSpeed']\n",
    "for i, condition in enumerate(conditions):\n",
    "    zscores = [\n",
    "        outlier_comparison[condition].get('addition_zscore', 0),\n",
    "        outlier_comparison[condition].get('specialization_zscore', 0),\n",
    "        outlier_comparison[condition].get('epochs_zscore', 0)\n",
    "    ]\n",
    "    \n",
    "    ax5.plot(range(len(metrics)), zscores, 'o-', label=condition.replace('_', ' ').title(), markersize=8)\n",
    "\n",
    "ax5.axhline(2, color='red', linestyle='--', alpha=0.5, label='Outlier threshold')\n",
    "ax5.axhline(-2, color='red', linestyle='--', alpha=0.5)\n",
    "ax5.axhline(0, color='black', linestyle='-', alpha=0.3)\n",
    "ax5.set_xticks(range(len(metrics)))\n",
    "ax5.set_xticklabels(metrics, fontsize=9)\n",
    "ax5.set_ylabel('Z-Score')\n",
    "ax5.set_title(f'Outlier Analysis: Seed {OUTLIER_SEED} vs Normal Seeds')\n",
    "ax5.legend(fontsize=8)\n",
    "ax5.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 6: Frequency distribution comparison\n",
    "ax6 = fig.add_subplot(gs[2, 1:])\n",
    "\n",
    "# Show frequency distributions for seed 42 (representative)\n",
    "seed_to_plot = 42\n",
    "x_offset = 0\n",
    "\n",
    "for condition in conditions:\n",
    "    freqs = fourier_results[seed_to_plot][condition]['neuron_freqs']\n",
    "    unique, counts = np.unique(freqs, return_counts=True)\n",
    "    \n",
    "    ax6.bar(unique + x_offset, counts, width=0.8, \n",
    "            label=condition.replace('_', ' ').title(), alpha=0.7)\n",
    "    x_offset += 0.3\n",
    "\n",
    "ax6.set_xlabel('Frequency')\n",
    "ax6.set_ylabel('Number of Neurons')\n",
    "ax6.set_title(f'Frequency Distribution (Seed {seed_to_plot})')\n",
    "ax6.legend()\n",
    "ax6.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.suptitle('Comprehensive 5-Seed Transfer Learning Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "plt.savefig(f'{EXPERIMENT_DIR}/figures/comprehensive_5seed_analysis.png', \n",
    "            dpi=300, bbox_inches='tight')\n",
    "print(\"\u2713 Saved: comprehensive_5seed_analysis.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Statistical Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical significance tests\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STATISTICAL SIGNIFICANCE TESTS (NORMAL SEEDS ONLY)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Test 1: Does grokked transfer learn faster than random?\n",
    "print(\"\\n1. Convergence Speed: Grokked vs Random\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "grok_epochs = normal_stats['grokked_transfer']['epochs_to_999']\n",
    "rand_epochs = normal_stats['random_baseline']['epochs_to_999']\n",
    "\n",
    "if len(grok_epochs) >= 2 and len(rand_epochs) >= 2:\n",
    "    t_stat, p_value = ttest_ind(grok_epochs, rand_epochs)\n",
    "    speedup = np.mean(rand_epochs) / np.mean(grok_epochs)\n",
    "    \n",
    "    print(f\"Grokked: {np.mean(grok_epochs):.0f} \u00b1 {np.std(grok_epochs):.0f} epochs\")\n",
    "    print(f\"Random:  {np.mean(rand_epochs):.0f} \u00b1 {np.std(rand_epochs):.0f} epochs\")\n",
    "    print(f\"\\nSpeedup: {speedup:.2f}x faster\")\n",
    "    print(f\"t-statistic: {t_stat:.3f}\")\n",
    "    print(f\"p-value: {p_value:.4f}\")\n",
    "    \n",
    "    if p_value < 0.05:\n",
    "        print(\"\u2713 SIGNIFICANT difference (p < 0.05)\")\n",
    "    else:\n",
    "        print(\"\u2192 Not significant (p >= 0.05)\")\n",
    "\n",
    "# Test 2: Does grokked have lower specialization?\n",
    "print(\"\\n2. Circuit Specialization: Grokked vs Memorized\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "grok_spec = normal_stats['grokked_transfer']['mean_specialization']\n",
    "mem_spec = normal_stats['memorized_transfer']['mean_specialization']\n",
    "\n",
    "if len(grok_spec) >= 2 and len(mem_spec) >= 2:\n",
    "    t_stat, p_value = ttest_ind(grok_spec, mem_spec)\n",
    "    \n",
    "    print(f\"Grokked:   {np.mean(grok_spec):.3f} \u00b1 {np.std(grok_spec):.3f}\")\n",
    "    print(f\"Memorized: {np.mean(mem_spec):.3f} \u00b1 {np.std(mem_spec):.3f}\")\n",
    "    print(f\"\\nt-statistic: {t_stat:.3f}\")\n",
    "    print(f\"p-value: {p_value:.4f}\")\n",
    "    \n",
    "    if p_value < 0.05:\n",
    "        if np.mean(grok_spec) < np.mean(mem_spec):\n",
    "            print(\"\u2713 SIGNIFICANT: Grokked has LOWER specialization (more general)\")\n",
    "        else:\n",
    "            print(\"\u2713 SIGNIFICANT: Grokked has HIGHER specialization\")\n",
    "    else:\n",
    "        print(\"\u2192 Not significant (p >= 0.05)\")\n",
    "\n",
    "# Test 3: Addition retention\n",
    "print(\"\\n3. Addition Retention: Grokked vs Memorized vs Random\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "grok_add = normal_stats['grokked_transfer']['addition_test_acc']\n",
    "mem_add = normal_stats['memorized_transfer']['addition_test_acc']\n",
    "rand_add = normal_stats['random_baseline']['addition_test_acc']\n",
    "\n",
    "print(f\"Grokked:   {np.mean(grok_add)*100:.2f}% \u00b1 {np.std(grok_add)*100:.2f}%\")\n",
    "print(f\"Memorized: {np.mean(mem_add)*100:.2f}% \u00b1 {np.std(mem_add)*100:.2f}%\")\n",
    "print(f\"Random:    {np.mean(rand_add)*100:.2f}% \u00b1 {np.std(rand_add)*100:.2f}%\")\n",
    "print(f\"Random chance: {100/113:.2f}%\")\n",
    "\n",
    "# Check if all at random chance\n",
    "random_chance = 1/113\n",
    "all_at_random = (\n",
    "    abs(np.mean(grok_add) - random_chance) < 0.02 and\n",
    "    abs(np.mean(mem_add) - random_chance) < 0.02 and\n",
    "    abs(np.mean(rand_add) - random_chance) < 0.02\n",
    ")\n",
    "\n",
    "if all_at_random:\n",
    "    print(\"\\n\u2713 All conditions at random chance - COMPLETE CATASTROPHIC FORGETTING\")\n",
    "else:\n",
    "    # Test if grokked > others\n",
    "    if len(grok_add) >= 2 and len(mem_add) >= 2:\n",
    "        t_stat, p_value = ttest_ind(grok_add, mem_add)\n",
    "        print(f\"\\nGrokked vs Memorized: t={t_stat:.3f}, p={p_value:.4f}\")\n",
    "        if p_value < 0.05 and np.mean(grok_add) > np.mean(mem_add):\n",
    "            print(\"\u2713 SIGNIFICANT: Grokked retains MORE addition knowledge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPREHENSIVE ANALYSIS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n1. ADDITION RETENTION (Catastrophic Forgetting):\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for condition in conditions:\n",
    "    accs = normal_stats[condition]['addition_test_acc']\n",
    "    print(f\"{condition.replace('_', ' ').title()}:\")\n",
    "    print(f\"  Normal seeds: {np.mean(accs)*100:.2f}% \u00b1 {np.std(accs)*100:.2f}%\")\n",
    "    \n",
    "    outlier_acc = addition_results[OUTLIER_SEED][condition]['test_acc']\n",
    "    print(f\"  Outlier seed {OUTLIER_SEED}: {outlier_acc*100:.2f}%\")\n",
    "    \n",
    "    if np.mean(accs) > 0.5:\n",
    "        print(f\"  \u2192 RETENTION: Partial knowledge preserved\")\n",
    "    elif abs(np.mean(accs) - 1/113) < 0.02:\n",
    "        print(f\"  \u2192 COMPLETE FORGETTING: At random chance ({100/113:.2f}%)\")\n",
    "    else:\n",
    "        print(f\"  \u2192 CATASTROPHIC FORGETTING: Below 50% but above random\")\n",
    "\n",
    "print(\"\\n2. CONVERGENCE SPEED:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "fastest_condition = min(conditions, \n",
    "                       key=lambda c: np.mean(normal_stats[c]['epochs_to_999']) \n",
    "                       if normal_stats[c]['epochs_to_999'] else float('inf'))\n",
    "\n",
    "for condition in conditions:\n",
    "    epochs = normal_stats[condition]['epochs_to_999']\n",
    "    if epochs:\n",
    "        print(f\"{condition.replace('_', ' ').title()}: {np.mean(epochs):.0f} \u00b1 {np.std(epochs):.0f} epochs\")\n",
    "\n",
    "print(f\"\\n\u2192 FASTEST: {fastest_condition.replace('_', ' ').title()}\")\n",
    "\n",
    "grok_epochs = normal_stats['grokked_transfer']['epochs_to_999']\n",
    "rand_epochs = normal_stats['random_baseline']['epochs_to_999']\n",
    "if grok_epochs and rand_epochs:\n",
    "    speedup = np.mean(rand_epochs) / np.mean(grok_epochs)\n",
    "    print(f\"\u2192 Transfer learning speedup: {speedup:.2f}x faster than random init\")\n",
    "\n",
    "print(\"\\n3. CIRCUIT PROPERTIES:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for condition in conditions:\n",
    "    specs = normal_stats[condition]['mean_specialization']\n",
    "    print(f\"{condition.replace('_', ' ').title()}:\")\n",
    "    print(f\"  Mean specialization: {np.mean(specs):.3f} \u00b1 {np.std(specs):.3f}\")\n",
    "    \n",
    "    if np.mean(specs) > 0.9:\n",
    "        print(f\"  \u2192 HYPER-SPECIALIZED: Overfitted to specific patterns\")\n",
    "    elif np.mean(specs) < 0.7:\n",
    "        print(f\"  \u2192 GENERAL: Distributed representations\")\n",
    "    else:\n",
    "        print(f\"  \u2192 MODERATE: Balanced specialization\")\n",
    "\n",
    "print(\"\\n4. PREDICTION PATTERNS:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Count seeds where all models agree\n",
    "high_agreement_seeds = []\n",
    "for seed in SEEDS:\n",
    "    if (prediction_agreements[seed]['grok_vs_mem'] > 0.95 and \n",
    "        prediction_agreements[seed]['grok_vs_rand'] > 0.95):\n",
    "        high_agreement_seeds.append(seed)\n",
    "\n",
    "if len(high_agreement_seeds) >= 4:\n",
    "    print(f\"\u2713 In {len(high_agreement_seeds)}/{len(SEEDS)} seeds, all models produce IDENTICAL predictions\")\n",
    "    print(f\"  Seeds with high agreement: {high_agreement_seeds}\")\n",
    "    print(f\"  \u2192 All models converged to the SAME subtraction circuit\")\n",
    "    print(f\"  \u2192 This circuit produces identical outputs on addition inputs\")\n",
    "else:\n",
    "    print(f\"\u2192 Models produce different predictions in most seeds\")\n",
    "\n",
    "print(\"\\n5. OUTLIER ANALYSIS:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "outlier_detected = False\n",
    "for condition in conditions:\n",
    "    significant_diffs = []\n",
    "    for metric, zscore in outlier_comparison[condition].items():\n",
    "        if abs(zscore) > 2:\n",
    "            significant_diffs.append(f\"{metric} (z={zscore:.2f})\")\n",
    "            outlier_detected = True\n",
    "    \n",
    "    if significant_diffs:\n",
    "        print(f\"{condition.replace('_', ' ').title()}:\")\n",
    "        for diff in significant_diffs:\n",
    "            print(f\"  \u26a0\ufe0f  {diff}\")\n",
    "\n",
    "if not outlier_detected:\n",
    "    print(f\"\u2192 Seed {OUTLIER_SEED} shows NO significant outlier behavior (all |z| < 2)\")\n",
    "    print(f\"  All seeds behave similarly despite different random initializations\")\n",
    "\n",
    "print(\"\\n6. KEY SCIENTIFIC FINDINGS:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Finding 1: Transfer speed\n",
    "if grok_epochs and rand_epochs:\n",
    "    if np.mean(grok_epochs) < np.mean(rand_epochs):\n",
    "        print(\"\\n\u2713 FINDING 1: Transfer learning accelerates convergence\")\n",
    "        print(f\"  Grokked models learn subtraction {speedup:.2f}x faster than random init\")\n",
    "        print(f\"  Inherited circuits provide learning efficiency, not task retention\")\n",
    "\n",
    "# Finding 2: Catastrophic forgetting\n",
    "grok_add_mean = np.mean(normal_stats['grokked_transfer']['addition_test_acc'])\n",
    "if abs(grok_add_mean - 1/113) < 0.02:\n",
    "    print(\"\\n\u2713 FINDING 2: Complete catastrophic forgetting\")\n",
    "    print(f\"  All models at random chance ({grok_add_mean*100:.2f}%) on addition\")\n",
    "    print(f\"  Addition and subtraction use DISTINCT neural circuits\")\n",
    "    print(f\"  Transfer learning does NOT preserve multi-task capability\")\n",
    "\n",
    "# Finding 3: Circuit convergence\n",
    "if len(high_agreement_seeds) >= 4:\n",
    "    print(\"\\n\u2713 FINDING 3: Convergent circuit formation\")\n",
    "    print(f\"  Different initializations converge to the same subtraction solution\")\n",
    "    print(f\"  Evidence: {len(high_agreement_seeds)}/{len(SEEDS)} seeds show 100% prediction agreement\")\n",
    "    print(f\"  Subtraction has a dominant basin of attraction in loss landscape\")\n",
    "\n",
    "# Finding 4: Specialization patterns\n",
    "grok_spec_mean = np.mean(normal_stats['grokked_transfer']['mean_specialization'])\n",
    "mem_spec_mean = np.mean(normal_stats['memorized_transfer']['mean_specialization'])\n",
    "\n",
    "if mem_spec_mean > grok_spec_mean + 0.05:\n",
    "    print(\"\\n\u2713 FINDING 4: Grokked circuits are more general\")\n",
    "    print(f\"  Grokked specialization: {grok_spec_mean:.3f}\")\n",
    "    print(f\"  Memorized specialization: {mem_spec_mean:.3f}\")\n",
    "    print(f\"  Grokked models maintain lower specialization from source\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYSIS COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Relearning Analysis\n",
    "\n",
    "**Question**: After learning subtraction and forgetting addition, how quickly can models RELEARN addition?\n",
    "\n",
    "This tests:\n",
    "- Whether catastrophic forgetting is reversible\n",
    "- If grokked models can relearn faster (latent structure)\n",
    "- Comparing plasticity across conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relearning experiment: Train models back on addition\n",
    "from torch import optim\n",
    "from transformers import full_loss\n",
    "import copy\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RELEARNING ANALYSIS: How fast can models relearn addition?\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def train_relearning(model, config, max_epochs=3000, target_acc=0.95):\n",
    "    \"\"\"Train model to relearn addition task.\"\"\"\n",
    "    model.to(config.device)\n",
    "    model.train()\n",
    "\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=config.lr,\n",
    "                           weight_decay=config.weight_decay, betas=(0.9, 0.98))\n",
    "    scheduler = optim.lr_scheduler.LambdaLR(optimizer, lambda step: min(step/10, 1))\n",
    "\n",
    "    train_data, test_data = gen_train_test(config)\n",
    "    test_tensor = torch.tensor(test_data).to(config.device)\n",
    "\n",
    "    test_accuracies = []\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        # Train step\n",
    "        train_loss = full_loss(config, model, train_data)\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Evaluate\n",
    "        if epoch % 10 == 0 or epoch < 100:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                logits = model(test_tensor)\n",
    "                predictions = logits[:, -1, :config.p].argmax(dim=-1)\n",
    "                targets = torch.tensor([config.fn(a, b) for a, b, _ in test_data]).to(config.device)\n",
    "                test_acc = (predictions == targets).float().mean().item()\n",
    "            model.train()\n",
    "\n",
    "            test_accuracies.append(test_acc)\n",
    "\n",
    "            # Check if reached target\n",
    "            if test_acc >= target_acc:\n",
    "                print(f\"    Reached {target_acc*100:.0f}% at epoch {epoch}\")\n",
    "                return {\n",
    "                    'epochs_to_target': epoch,\n",
    "                    'final_accuracy': test_acc,\n",
    "                    'test_accuracies': test_accuracies,\n",
    "                    'converged': True\n",
    "                }\n",
    "\n",
    "    return {\n",
    "        'epochs_to_target': None,\n",
    "        'final_accuracy': test_accuracies[-1] if test_accuracies else 0,\n",
    "        'test_accuracies': test_accuracies,\n",
    "        'converged': False\n",
    "    }\n",
    "\n",
    "# Test relearning on one representative seed\n",
    "RELEARN_SEED = 42\n",
    "print(f\"\\nTesting relearning on seed {RELEARN_SEED}...\")\n",
    "print(\"(This may take a few minutes per condition)\\n\")\n",
    "\n",
    "relearning_results = {}\n",
    "\n",
    "for condition in conditions:\n",
    "    print(f\"\\n{condition.replace('_', ' ').title()}:\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    # Make a copy of the model to avoid modifying the original\n",
    "    original_model = all_models[RELEARN_SEED][condition]['model']\n",
    "    model_copy = copy.deepcopy(original_model)\n",
    "\n",
    "    # Create addition config for relearning\n",
    "    relearn_config = replace(addition_config, seed=RELEARN_SEED)\n",
    "\n",
    "    print(f\"  Starting accuracy on addition: {addition_results[RELEARN_SEED][condition]['test_acc']*100:.2f}%\")\n",
    "    print(f\"  Retraining on addition task...\")\n",
    "\n",
    "    # Train to relearn addition\n",
    "    results = train_relearning(model_copy, relearn_config, max_epochs=3000, target_acc=0.95)\n",
    "\n",
    "    relearning_results[condition] = results\n",
    "\n",
    "    if results['converged']:\n",
    "        print(f\"  \u2713 Successfully relearned addition in {results['epochs_to_target']} epochs\")\n",
    "    else:\n",
    "        print(f\"  \u2717 Did not converge to 95% in 3000 epochs (final: {results['final_accuracy']*100:.2f}%)\")\n",
    "\n",
    "    # Clean up\n",
    "    del model_copy\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RELEARNING SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Compare relearning speeds\n",
    "for condition in conditions:\n",
    "    epochs = relearning_results[condition]['epochs_to_target']\n",
    "    final_acc = relearning_results[condition]['final_accuracy']\n",
    "\n",
    "    print(f\"\\n{condition.replace('_', ' ').title()}:\")\n",
    "    if epochs is not None:\n",
    "        print(f\"  Epochs to 95%: {epochs}\")\n",
    "    else:\n",
    "        print(f\"  Did not converge (final: {final_acc*100:.2f}%)\")\n",
    "\n",
    "# Determine fastest\n",
    "converged = {c: relearning_results[c]['epochs_to_target']\n",
    "             for c in conditions if relearning_results[c]['epochs_to_target'] is not None}\n",
    "\n",
    "if converged:\n",
    "    fastest = min(converged, key=converged.get)\n",
    "    slowest = max(converged, key=converged.get)\n",
    "    speedup = converged[slowest] / converged[fastest]\n",
    "\n",
    "    print(f\"\\nFASTEST: {fastest.replace('_', ' ').title()} ({converged[fastest]} epochs)\")\n",
    "    print(f\"SLOWEST: {slowest.replace('_', ' ').title()} ({converged[slowest]} epochs)\")\n",
    "    print(f\"\\nSpeedup: {speedup:.2f}x\")\n",
    "\n",
    "    if 'grokked_transfer' in converged and 'random_baseline' in converged:\n",
    "        grok_vs_rand = converged['random_baseline'] / converged['grokked_transfer']\n",
    "        print(f\"\\nGrokked vs Random speedup: {grok_vs_rand:.2f}x\")\n",
    "\n",
    "        if grok_vs_rand > 1.2:\n",
    "            print(\"\u2713 Grokked models relearn addition FASTER\")\n",
    "            print(\"  \u2192 Latent structure from original grokking helps relearning\")\n",
    "        elif grok_vs_rand < 0.8:\n",
    "            print(\"\u26a0\ufe0f  Grokked models relearn SLOWER\")\n",
    "            print(\"  \u2192 Subtraction training may have damaged latent addition structure\")\n",
    "        else:\n",
    "            print(\"\u2192 Similar relearning speed across conditions\")\n",
    "            print(\"  \u2192 No advantage from grokked initialization for relearning\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to file\n",
    "import json\n",
    "\n",
    "results_summary = {\n",
    "    'seeds_analyzed': SEEDS,\n",
    "    'normal_seeds': NORMAL_SEEDS,\n",
    "    'outlier_seed': OUTLIER_SEED,\n",
    "    'normal_stats': {\n",
    "        condition: {\n",
    "            'addition_retention_mean': float(np.mean(normal_stats[condition]['addition_test_acc'])),\n",
    "            'addition_retention_std': float(np.std(normal_stats[condition]['addition_test_acc'])),\n",
    "            'specialization_mean': float(np.mean(normal_stats[condition]['mean_specialization'])),\n",
    "            'specialization_std': float(np.std(normal_stats[condition]['mean_specialization'])),\n",
    "            'epochs_to_999_mean': float(np.mean(normal_stats[condition]['epochs_to_999'])) if normal_stats[condition]['epochs_to_999'] else None,\n",
    "            'epochs_to_999_std': float(np.std(normal_stats[condition]['epochs_to_999'])) if normal_stats[condition]['epochs_to_999'] else None,\n",
    "        }\n",
    "        for condition in conditions\n",
    "    },\n",
    "    'outlier_comparison': {\n",
    "        condition: {\n",
    "            k: float(v) for k, v in outlier_comparison[condition].items()\n",
    "        }\n",
    "        for condition in conditions\n",
    "    },\n",
    "    'prediction_agreements': {\n",
    "        str(seed): {\n",
    "            k: float(v) for k, v in prediction_agreements[seed].items()\n",
    "        }\n",
    "        for seed in SEEDS\n",
    "    }\n",
    "}\n",
    "\n",
    "output_path = f'{EXPERIMENT_DIR}/results/comprehensive_5seed_summary.json'\n",
    "with open(output_path, 'w') as f:\n",
    "    json.dump(results_summary, f, indent=2)\n",
    "\n",
    "print(f\"\\n\u2713 Saved comprehensive results to: {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}